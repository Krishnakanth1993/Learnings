{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishnakanth1993/Learnings/blob/main/MNIST_Model/Reference/minimal_prameter_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "71979988",
      "metadata": {
        "id": "71979988"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a1e6168",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a1e6168",
        "outputId": "0c8595ed-8355-4809-c94f-919d7817d3a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ],
      "source": [
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdaddb2b",
      "metadata": {
        "id": "fdaddb2b"
      },
      "source": [
        "# **Understanding the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "086f9258",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "086f9258",
        "outputId": "36b4d73f-ac57-475b-e116-73fb5af5c86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 483kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.65MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.1307, Std: 0.3015 ,Total_images: 60000\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST training data without normalization\n",
        "train_data = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(train_data, batch_size=512, shuffle=False)\n",
        "\n",
        "# Compute mean and std\n",
        "mean = 0.0\n",
        "std = 0.0\n",
        "total_images = 0\n",
        "\n",
        "for images, _ in train_loader:\n",
        "    batch_samples = images.size(0)  # Number of images in batch\n",
        "    images = images.view(batch_samples, -1)  # Flatten: [batch_size, 1, 28, 28] -> [batch_size, 784]\n",
        "    mean += images.mean(dim=1).sum().item()  # Sum mean across pixels for each image\n",
        "    std += images.std(dim=1).sum().item()  # Sum std across pixels for each image\n",
        "    total_images += batch_samples\n",
        "\n",
        "mean /= total_images\n",
        "std /= total_images\n",
        "\n",
        "print(f'Mean: {mean:.4f}, Std: {std:.4f} ,Total_images: {total_images}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c4eadf10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4eadf10",
        "outputId": "b10e2861-65f1-4712-bd40-d0fef936c95c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a tensor in the batch: torch.Size([512, 1, 28, 28])\n",
            "Shape of a tensor in the batch: torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "dataloader_iterator = iter(train_loader)\n",
        "batch_data = next(dataloader_iterator)\n",
        "\n",
        "for item in batch_data:\n",
        "  if isinstance(item, torch.Tensor):\n",
        "      #print(item)\n",
        "      print(f\"Shape of a tensor in the batch: {item.shape}\")\n",
        "  else:\n",
        "      #print(item)\n",
        "      print(f\"Type of item in batch: {type(item)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c0c326a",
      "metadata": {
        "id": "8c0c326a"
      },
      "source": [
        "# **Data Loading & Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fdfd331a",
      "metadata": {
        "id": "fdfd331a"
      },
      "outputs": [],
      "source": [
        "# Train data transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomApply([transforms.CenterCrop(22), ], p=0.1),\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.RandomRotation((-15., 15.), fill=0),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    ])\n",
        "\n",
        "# Test data transformations\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize((0.1407,), (0.4081,)) # Mean: 0.1307, Std: 0.3015 ,Total_images: 60000 . Normalization must be uniform between train and test.\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a055412c",
      "metadata": {
        "id": "a055412c"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.MNIST('../data', train=True, download=True, transform=train_transforms)\n",
        "test_data = datasets.MNIST('../data', train=False, download=True, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "977d3bb5",
      "metadata": {
        "id": "977d3bb5"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "kwargs = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, **kwargs)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e1221165",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "e1221165",
        "outputId": "05104646-d2c9-4f71-e9c6-ea7d7f7cdf40"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch_data, batch_label = next(iter(train_loader))\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(12):\n",
        "  plt.subplot(3,4,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
        "  plt.title(batch_label[i].item())\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f07d7011",
      "metadata": {
        "id": "f07d7011"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "aeae542d",
      "metadata": {
        "id": "aeae542d"
      },
      "source": [
        "# **Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "93a44eee",
      "metadata": {
        "id": "93a44eee"
      },
      "outputs": [],
      "source": [
        "  class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) #28x28x1  | (3x3x1)32 | 28x28x32 RF 3x3\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1) #28x28x32 | (3x3x32)x32 | 28x28x32 RF 5x5\n",
        "        self.conv3 = nn.Conv2d(32, 16, kernel_size=3, padding=1) #14x14x32 | (3x3x32)x16 | 14x14x16 RF 10x10\n",
        "        self.conv4 = nn.Conv2d(16, 16, kernel_size=3, padding=1) #14x14x16  | (3x3x16)16 | 14x14x16 RF 12x12\n",
        "        self.conv5 = nn.Conv2d(16, 8, kernel_size=3, padding=1) #7x7x16  | (3x3x16)x8 | 7x7x8 RF 24x24\n",
        "        self.conv6 = nn.Conv2d(8, 8, kernel_size=3, padding=1) #7x7x8 | (3x3x8)x8 | 7x7x8 RF 26x26\n",
        "        self.fc1 = nn.Linear(8 * 7 * 7, 10) #RF 26x26\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = x.view(-1, 8 * 7 * 7)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "da44da61",
      "metadata": {
        "id": "da44da61"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d8eab0e3",
      "metadata": {
        "id": "d8eab0e3"
      },
      "source": [
        "# Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "df76a833",
      "metadata": {
        "id": "df76a833"
      },
      "outputs": [],
      "source": [
        "# Data to plot accuracy and loss graphs\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "test_incorrect_pred = {'images': [], 'ground_truths': [], 'predicted_vals': []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "174223af",
      "metadata": {
        "id": "174223af"
      },
      "outputs": [],
      "source": [
        "# Define GetCorrectPredCount\n",
        "def GetCorrectPredCount(pPrediction, pLabels):\n",
        "    return pPrediction.argmax(dim=1).eq(pLabels).sum().item()\n",
        "\n",
        "# Training function\n",
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Predict\n",
        "        pred = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(pred, target)  # Shape: [batch_size]\n",
        "        train_loss += loss.sum().item()  # Sum per-sample losses for reporting\n",
        "        loss = loss.mean()  # Average for backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct += GetCorrectPredCount(pred, target)\n",
        "        processed += len(data)\n",
        "\n",
        "        pbar.set_description(desc=f'Train: Loss={loss.item():0.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "\n",
        "    train_acc.append(100 * correct / processed)\n",
        "    train_losses.append(train_loss / len(train_loader.dataset))  # Average per sample\n",
        "\n",
        "# Test function\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)  # Shape: [batch_size]\n",
        "            test_loss += loss.sum().item()  # Sum per-sample losses\n",
        "            correct += GetCorrectPredCount(output, target)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  # Average per sample\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3bd2dd6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3bd2dd6c",
        "outputId": "65377494-3516-4b21-adea-17319ccad59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.1043 Batch_id=117 Accuracy=75.95: 100%|██████████| 118/118 [00:17<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.1579, Accuracy: 9528/10000 (95.28%)\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.1430 Batch_id=117 Accuracy=95.03: 100%|██████████| 118/118 [00:19<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0842, Accuracy: 9733/10000 (97.33%)\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.1796 Batch_id=117 Accuracy=96.64: 100%|██████████| 118/118 [00:18<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0688, Accuracy: 9786/10000 (97.86%)\n",
            "\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.0133 Batch_id=117 Accuracy=96.81: 100%|██████████| 118/118 [00:17<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0642, Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.2255 Batch_id=117 Accuracy=96.92: 100%|██████████| 118/118 [00:18<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0641, Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.0887 Batch_id=117 Accuracy=96.99: 100%|██████████| 118/118 [00:17<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0641, Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.0450 Batch_id=117 Accuracy=96.92: 100%|██████████| 118/118 [00:17<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0640, Accuracy: 9801/10000 (98.01%)\n",
            "\n",
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.1205 Batch_id=117 Accuracy=96.96: 100%|██████████| 118/118 [00:19<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0638, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.0782 Batch_id=117 Accuracy=96.97: 100%|██████████| 118/118 [00:17<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0638, Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.0854 Batch_id=117 Accuracy=96.97: 100%|██████████| 118/118 [00:19<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0638, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.1192 Batch_id=117 Accuracy=97.00: 100%|██████████| 118/118 [00:19<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0638, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.1752 Batch_id=117 Accuracy=96.94: 100%|██████████| 118/118 [00:18<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0638, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.0469 Batch_id=117 Accuracy=97.02: 100%|██████████| 118/118 [00:18<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0638, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: Loss=0.1154 Batch_id=117 Accuracy=97.05: 100%|██████████| 118/118 [00:18<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3024403282.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-87163717.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, criterion)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "num_epoch = 20\n",
        "# Training loop for 10 epochs\n",
        "for epoch in range(1, num_epoch+1):\n",
        "    print(f'Epoch {epoch}')\n",
        "    train(model, device, train_loader, optimizer, criterion)\n",
        "    test(model, device, test_loader, criterion)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72abc083",
      "metadata": {
        "id": "72abc083"
      },
      "source": [
        "# Test Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b120e0",
      "metadata": {
        "id": "44b120e0"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "axs[0, 0].plot(train_losses)\n",
        "axs[0, 0].set_title(\"Training Loss\")\n",
        "axs[1, 0].plot(train_acc)\n",
        "axs[1, 0].set_title(\"Training Accuracy\")\n",
        "axs[0, 1].plot(test_losses)\n",
        "axs[0, 1].set_title(\"Test Loss\")\n",
        "axs[1, 1].plot(test_acc)\n",
        "axs[1, 1].set_title(\"Test Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8c17ccfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c17ccfa",
        "outputId": "9f49619c-31f7-41be-ae16-88fd77761a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 32, 28, 28]           9,248\n",
            "            Conv2d-3           [-1, 16, 14, 14]           4,624\n",
            "            Conv2d-4           [-1, 16, 14, 14]           2,320\n",
            "            Conv2d-5              [-1, 8, 7, 7]           1,160\n",
            "            Conv2d-6              [-1, 8, 7, 7]             584\n",
            "            Linear-7                   [-1, 10]           3,930\n",
            "================================================================\n",
            "Total params: 22,186\n",
            "Trainable params: 22,186\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.44\n",
            "Params size (MB): 0.08\n",
            "Estimated Total Size (MB): 0.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "191fdfd5",
      "metadata": {
        "id": "191fdfd5"
      },
      "source": [
        "# Save and Visualize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "474c561c",
      "metadata": {
        "id": "474c561c"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"model.pt\") ## does not include details of activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83cfc1e4",
      "metadata": {
        "id": "83cfc1e4",
        "outputId": "2391cda4-fbda-4df7-d3e3-2cdbae9fe7bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3254252982.py:7: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(model, dummy_input, \"model.onnx\",\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Create dummy input with the same shape as your input\n",
        "dummy_input = torch.randn(1, 1, 28, 28).to(device)  # Batch x Channels x Height x Width\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model, dummy_input, \"model.onnx\",\n",
        "                  input_names=['input'],\n",
        "                  output_names=['output'],\n",
        "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
        "                  opset_version=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "202abc10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "202abc10",
        "outputId": "85087683-c265-449f-aa2a-93f9f53807a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=392, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343b7e70",
      "metadata": {
        "id": "343b7e70",
        "outputId": "e50cc24a-58b7-4784-ce9e-7ea877e6656e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}