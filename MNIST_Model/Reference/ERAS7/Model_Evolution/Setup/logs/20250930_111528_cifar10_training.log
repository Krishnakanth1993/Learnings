2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Setup\logs\20250930_111528_cifar10_training.log
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - Updated Configuration (from main()):
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Epochs: 100
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Optimizer: SGD
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Scheduler: StepLR
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Step Size: 30
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Batch Size: 512
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Num Workers: 4
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Pin Memory: True
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Shuffle: True
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Dropout Rate: 0.05
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Device: CUDA
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Setup\logs
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Setup\models
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Save Model: True
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO -   - Log Level: DEBUG
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - CIFAR-10 TRAINING EXPERIMENT STARTED
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=512, num_workers=4, pin_memory=True, shuffle=True, mean=(0.1307,), std=(0.3081,), cifar10_mean=(0.4914, 0.4822, 0.4465), cifar10_std=(0.247, 0.2435, 0.2616), rotation_range=(-7.0, 7.0), fill_value=1)
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - Model Config: ModelConfig(input_channels=1, input_size=(28, 28), num_classes=10, dropout_rate=0.05)
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - Training Config: TrainingConfig(epochs=100, learning_rate=0.05, momentum=0.9, weight_decay=0.0, scheduler_step_size=30, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='StepLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001)
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - Setting up data...
2025-09-30 11:15:28,161 - CIFAR-10_Training - INFO - Loading CIFAR-10 dataset...
2025-09-30 11:15:29,569 - CIFAR-10_Training - INFO - CIFAR-10 dataset loaded successfully!
2025-09-30 11:15:29,571 - CIFAR-10_Training - INFO - Train samples: 50000
2025-09-30 11:15:29,571 - CIFAR-10_Training - INFO - Test samples: 10000
2025-09-30 11:15:29,571 - CIFAR-10_Training - INFO - Computing CIFAR-10 data statistics...
2025-09-30 11:15:31,420 - CIFAR-10_Training - INFO - CIFAR-10 Data Statistics:
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   - Size: 153,600,000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   - Min: 0.0000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   - Max: 1.0000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   - Mean: 0.4734
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   - Std: 0.2516
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   - Variance: 0.0633
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO - Channel-wise Statistics:
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   Red Channel:
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Mean: 0.4914
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Std: 0.2470
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   Green Channel:
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Mean: 0.4822
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Std: 0.2435
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -   Blue Channel:
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Mean: 0.4465
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Std: 0.2616
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 11:15:31,423 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 11:15:44,677 - CIFAR-10_Training - INFO - CIFAR-10 Batch Information:
2025-09-30 11:15:44,677 - CIFAR-10_Training - INFO -   - Batch size: 512
2025-09-30 11:15:44,677 - CIFAR-10_Training - INFO -   - Image shape: torch.Size([3, 32, 32])
2025-09-30 11:15:44,677 - CIFAR-10_Training - INFO -   - Label shape: torch.Size([512])
2025-09-30 11:15:44,677 - CIFAR-10_Training - INFO -   - Data type: torch.float32
2025-09-30 11:15:44,677 - CIFAR-10_Training - INFO -   - Number of classes: 10
2025-09-30 11:15:45,625 - CIFAR-10_Training - INFO - Getting input size from CIFAR-10 data loader...
2025-09-30 11:15:56,840 - CIFAR-10_Training - INFO - CIFAR-10 input size from data loader: (3, 32, 32)
2025-09-30 11:15:57,814 - CIFAR-10_Training - INFO - Setting up model...
2025-09-30 11:15:57,853 - CIFAR-10_Training - INFO - Generating model summary...
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO - Model Architecture Summary:
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -   - Total Parameters: 602,628
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -   - Batch Normalization: Yes
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -   - Dropout: No
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -   - GAP Layers: No
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -   - FC Layers: Yes
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO - DETAILED MODEL ARCHITECTURE SUMMARY
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -         Layer (type)               Output Shape         Param #
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO - ================================================================
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -             Conv2d-1           [-1, 16, 32, 32]             432
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -        BatchNorm2d-2           [-1, 16, 32, 32]              32
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -               ReLU-3           [-1, 16, 32, 32]               0
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -             Conv2d-4           [-1, 32, 32, 32]           4,608
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -        BatchNorm2d-5           [-1, 32, 32, 32]              64
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -               ReLU-6           [-1, 32, 32, 32]               0
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -             Conv2d-7           [-1, 32, 32, 32]           9,216
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -        BatchNorm2d-8           [-1, 32, 32, 32]              64
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -               ReLU-9           [-1, 32, 32, 32]               0
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -            Conv2d-10           [-1, 32, 32, 32]           9,216
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -       BatchNorm2d-11           [-1, 32, 32, 32]              64
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -              ReLU-12           [-1, 32, 32, 32]               0
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -         MaxPool2d-13           [-1, 32, 16, 16]               0
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -            Conv2d-14           [-1, 64, 16, 16]          18,432
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -       BatchNorm2d-15           [-1, 64, 16, 16]             128
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -              ReLU-16           [-1, 64, 16, 16]               0
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -            Conv2d-17           [-1, 64, 16, 16]          36,864
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -       BatchNorm2d-18           [-1, 64, 16, 16]             128
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -              ReLU-19           [-1, 64, 16, 16]               0
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -            Conv2d-20           [-1, 64, 16, 16]          36,864
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -       BatchNorm2d-21           [-1, 64, 16, 16]             128
2025-09-30 11:15:58,386 - CIFAR-10_Training - INFO -              ReLU-22           [-1, 64, 16, 16]               0
2025-09-30 11:15:58,393 - CIFAR-10_Training - INFO -         MaxPool2d-23             [-1, 64, 8, 8]               0
2025-09-30 11:15:58,393 - CIFAR-10_Training - INFO -            Conv2d-24            [-1, 128, 8, 8]          73,728
2025-09-30 11:15:58,393 - CIFAR-10_Training - INFO -       BatchNorm2d-25            [-1, 128, 8, 8]             256
2025-09-30 11:15:58,394 - CIFAR-10_Training - INFO -              ReLU-26            [-1, 128, 8, 8]               0
2025-09-30 11:15:58,394 - CIFAR-10_Training - INFO -            Conv2d-27            [-1, 128, 8, 8]         147,456
2025-09-30 11:15:58,394 - CIFAR-10_Training - INFO -       BatchNorm2d-28            [-1, 128, 8, 8]             256
2025-09-30 11:15:58,395 - CIFAR-10_Training - INFO -              ReLU-29            [-1, 128, 8, 8]               0
2025-09-30 11:15:58,395 - CIFAR-10_Training - INFO -            Conv2d-30            [-1, 128, 8, 8]         147,456
2025-09-30 11:15:58,396 - CIFAR-10_Training - INFO -       BatchNorm2d-31            [-1, 128, 8, 8]             256
2025-09-30 11:15:58,396 - CIFAR-10_Training - INFO -              ReLU-32            [-1, 128, 8, 8]               0
2025-09-30 11:15:58,397 - CIFAR-10_Training - INFO -         MaxPool2d-33            [-1, 128, 4, 4]               0
2025-09-30 11:15:58,397 - CIFAR-10_Training - INFO -            Conv2d-34             [-1, 64, 4, 4]          73,728
2025-09-30 11:15:58,397 - CIFAR-10_Training - INFO -       BatchNorm2d-35             [-1, 64, 4, 4]             128
2025-09-30 11:15:58,398 - CIFAR-10_Training - INFO -              ReLU-36             [-1, 64, 4, 4]               0
2025-09-30 11:15:58,398 - CIFAR-10_Training - INFO -            Conv2d-37             [-1, 32, 4, 4]          18,432
2025-09-30 11:15:58,399 - CIFAR-10_Training - INFO -       BatchNorm2d-38             [-1, 32, 4, 4]              64
2025-09-30 11:15:58,399 - CIFAR-10_Training - INFO -              ReLU-39             [-1, 32, 4, 4]               0
2025-09-30 11:15:58,400 - CIFAR-10_Training - INFO -            Conv2d-40             [-1, 16, 4, 4]           4,608
2025-09-30 11:15:58,400 - CIFAR-10_Training - INFO -       BatchNorm2d-41             [-1, 16, 4, 4]              32
2025-09-30 11:15:58,400 - CIFAR-10_Training - INFO -              ReLU-42             [-1, 16, 4, 4]               0
2025-09-30 11:15:58,401 - CIFAR-10_Training - INFO -            Conv2d-43            [-1, 128, 4, 4]          18,432
2025-09-30 11:15:58,401 - CIFAR-10_Training - INFO -       BatchNorm2d-44            [-1, 128, 4, 4]             256
2025-09-30 11:15:58,401 - CIFAR-10_Training - INFO -              ReLU-45            [-1, 128, 4, 4]               0
2025-09-30 11:15:58,402 - CIFAR-10_Training - INFO -            Conv2d-46             [-1, 10, 4, 4]           1,280
2025-09-30 11:15:58,402 - CIFAR-10_Training - INFO -       BatchNorm2d-47             [-1, 10, 4, 4]              20
2025-09-30 11:15:58,402 - CIFAR-10_Training - INFO -              ReLU-48             [-1, 10, 4, 4]               0
2025-09-30 11:15:58,403 - CIFAR-10_Training - INFO - AdaptiveAvgPool2d-49             [-1, 10, 1, 1]               0
2025-09-30 11:15:58,403 - CIFAR-10_Training - INFO - ================================================================
2025-09-30 11:15:58,405 - CIFAR-10_Training - INFO - Total params: 602,628
2025-09-30 11:15:58,405 - CIFAR-10_Training - INFO - Trainable params: 602,628
2025-09-30 11:15:58,405 - CIFAR-10_Training - INFO - Non-trainable params: 0
2025-09-30 11:15:58,406 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 11:15:58,406 - CIFAR-10_Training - INFO - Input size (MB): 0.01
2025-09-30 11:15:58,406 - CIFAR-10_Training - INFO - Forward/backward pass size (MB): 4.51
2025-09-30 11:15:58,406 - CIFAR-10_Training - INFO - Params size (MB): 2.30
2025-09-30 11:15:58,406 - CIFAR-10_Training - INFO - Estimated Total Size (MB): 6.82
2025-09-30 11:15:58,406 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 11:15:58,409 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:15:58,409 - CIFAR-10_Training - INFO - Setting up trainer...
2025-09-30 11:15:58,415 - CIFAR-10_Training - INFO - Using device: cuda
2025-09-30 11:15:58,417 - CIFAR-10_Training - INFO - Early stopping: Stop if train_acc - test_acc > 15.0% for 10 epochs
2025-09-30 11:15:58,417 - CIFAR-10_Training - INFO - Starting training process...
2025-09-30 11:15:58,417 - CIFAR-10_Training - INFO - Starting training process...
2025-09-30 11:15:58,417 - CIFAR-10_Training - INFO - Using optimizer: SGD
2025-09-30 11:15:58,417 - CIFAR-10_Training - INFO - Using scheduler: StepLR
2025-09-30 11:15:58,417 - CIFAR-10_Training - INFO - Optimizer Configuration:
2025-09-30 11:15:58,417 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-09-30 11:15:58,418 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-09-30 11:15:58,418 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-09-30 11:15:58,418 - CIFAR-10_Training - INFO - Scheduler Configuration:
2025-09-30 11:15:58,418 - CIFAR-10_Training - INFO -   - Step Size: 30
2025-09-30 11:15:58,419 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-09-30 11:15:58,419 - CIFAR-10_Training - INFO - Starting Epoch 1/100
2025-09-30 11:16:34,672 - CIFAR-10_Training - INFO - Epoch  1: Train Loss: 1.4916, Train Acc: 47.72%, Test Loss: 1.5020, Test Acc: 50.40%, Acc Diff: -2.68%, LR: 0.050000
2025-09-30 11:16:34,672 - CIFAR-10_Training - INFO - Starting Epoch 2/100
2025-09-30 11:17:09,216 - CIFAR-10_Training - INFO - Epoch  2: Train Loss: 0.9258, Train Acc: 68.38%, Test Loss: 1.0802, Test Acc: 64.14%, Acc Diff: 4.24%, LR: 0.050000
2025-09-30 11:17:09,216 - CIFAR-10_Training - INFO - Starting Epoch 3/100
2025-09-30 11:17:43,497 - CIFAR-10_Training - INFO - Epoch  3: Train Loss: 0.6795, Train Acc: 76.99%, Test Loss: 0.7913, Test Acc: 73.04%, Acc Diff: 3.95%, LR: 0.050000
2025-09-30 11:17:43,497 - CIFAR-10_Training - INFO - Starting Epoch 4/100
2025-09-30 11:18:17,859 - CIFAR-10_Training - INFO - Epoch  4: Train Loss: 0.5481, Train Acc: 81.67%, Test Loss: 0.7635, Test Acc: 74.29%, Acc Diff: 7.38%, LR: 0.050000
2025-09-30 11:18:17,859 - CIFAR-10_Training - INFO - Starting Epoch 5/100
2025-09-30 11:18:55,689 - CIFAR-10_Training - INFO - Epoch  5: Train Loss: 0.4535, Train Acc: 84.72%, Test Loss: 1.1682, Test Acc: 64.47%, Acc Diff: 20.25%, LR: 0.050000 (OVERFITTING: 1 epochs)
2025-09-30 11:18:55,689 - CIFAR-10_Training - INFO - Starting Epoch 6/100
2025-09-30 11:19:39,832 - CIFAR-10_Training - INFO - Epoch  6: Train Loss: 0.3829, Train Acc: 87.21%, Test Loss: 0.7139, Test Acc: 77.63%, Acc Diff: 9.58%, LR: 0.050000
2025-09-30 11:19:39,832 - CIFAR-10_Training - INFO - Starting Epoch 7/100
2025-09-30 11:20:22,879 - CIFAR-10_Training - INFO - Epoch  7: Train Loss: 0.3207, Train Acc: 89.38%, Test Loss: 0.7999, Test Acc: 75.59%, Acc Diff: 13.79%, LR: 0.050000
2025-09-30 11:20:22,879 - CIFAR-10_Training - INFO - Starting Epoch 8/100
2025-09-30 11:21:08,064 - CIFAR-10_Training - INFO - Epoch  8: Train Loss: 0.2587, Train Acc: 91.38%, Test Loss: 0.7218, Test Acc: 77.90%, Acc Diff: 13.48%, LR: 0.050000
2025-09-30 11:21:08,065 - CIFAR-10_Training - INFO - Starting Epoch 9/100
2025-09-30 11:21:49,937 - CIFAR-10_Training - INFO - Epoch  9: Train Loss: 0.2156, Train Acc: 92.88%, Test Loss: 0.6979, Test Acc: 79.54%, Acc Diff: 13.34%, LR: 0.050000
2025-09-30 11:21:49,937 - CIFAR-10_Training - INFO - Starting Epoch 10/100
2025-09-30 11:22:27,413 - CIFAR-10_Training - INFO - Epoch 10: Train Loss: 0.1813, Train Acc: 93.96%, Test Loss: 0.8992, Test Acc: 75.06%, Acc Diff: 18.90%, LR: 0.050000 (OVERFITTING: 1 epochs)
2025-09-30 11:22:27,413 - CIFAR-10_Training - INFO - Starting Epoch 11/100
2025-09-30 11:23:07,415 - CIFAR-10_Training - INFO - Epoch 11: Train Loss: 0.1410, Train Acc: 95.41%, Test Loss: 0.8589, Test Acc: 77.19%, Acc Diff: 18.22%, LR: 0.050000 (OVERFITTING: 2 epochs)
2025-09-30 11:23:07,415 - CIFAR-10_Training - INFO - Starting Epoch 12/100
2025-09-30 11:23:44,595 - CIFAR-10_Training - INFO - Epoch 12: Train Loss: 0.1166, Train Acc: 96.13%, Test Loss: 0.8205, Test Acc: 78.29%, Acc Diff: 17.84%, LR: 0.050000 (OVERFITTING: 3 epochs)
2025-09-30 11:23:44,595 - CIFAR-10_Training - INFO - Starting Epoch 13/100
2025-09-30 11:24:23,713 - CIFAR-10_Training - INFO - Epoch 13: Train Loss: 0.1015, Train Acc: 96.64%, Test Loss: 0.6494, Test Acc: 82.30%, Acc Diff: 14.34%, LR: 0.050000
2025-09-30 11:24:23,713 - CIFAR-10_Training - INFO - Starting Epoch 14/100
2025-09-30 11:25:05,545 - CIFAR-10_Training - INFO - Epoch 14: Train Loss: 0.0749, Train Acc: 97.59%, Test Loss: 0.9962, Test Acc: 75.74%, Acc Diff: 21.85%, LR: 0.050000 (OVERFITTING: 1 epochs)
2025-09-30 11:25:05,545 - CIFAR-10_Training - INFO - Starting Epoch 15/100
2025-09-30 11:25:42,471 - CIFAR-10_Training - INFO - Epoch 15: Train Loss: 0.0565, Train Acc: 98.29%, Test Loss: 0.8375, Test Acc: 79.98%, Acc Diff: 18.31%, LR: 0.050000 (OVERFITTING: 2 epochs)
2025-09-30 11:25:42,471 - CIFAR-10_Training - INFO - Starting Epoch 16/100
2025-09-30 11:26:25,506 - CIFAR-10_Training - INFO - Epoch 16: Train Loss: 0.0512, Train Acc: 98.44%, Test Loss: 0.9755, Test Acc: 77.79%, Acc Diff: 20.65%, LR: 0.050000 (OVERFITTING: 3 epochs)
2025-09-30 11:26:25,506 - CIFAR-10_Training - INFO - Starting Epoch 17/100
2025-09-30 11:27:07,520 - CIFAR-10_Training - INFO - Epoch 17: Train Loss: 0.0460, Train Acc: 98.53%, Test Loss: 0.7390, Test Acc: 82.15%, Acc Diff: 16.38%, LR: 0.050000 (OVERFITTING: 4 epochs)
2025-09-30 11:27:07,520 - CIFAR-10_Training - INFO - Starting Epoch 18/100
2025-09-30 11:27:44,355 - CIFAR-10_Training - INFO - Epoch 18: Train Loss: 0.0386, Train Acc: 98.86%, Test Loss: 0.7257, Test Acc: 82.82%, Acc Diff: 16.04%, LR: 0.050000 (OVERFITTING: 5 epochs)
2025-09-30 11:27:44,355 - CIFAR-10_Training - INFO - Starting Epoch 19/100
2025-09-30 11:28:26,917 - CIFAR-10_Training - INFO - Epoch 19: Train Loss: 0.0333, Train Acc: 98.98%, Test Loss: 0.8056, Test Acc: 81.35%, Acc Diff: 17.63%, LR: 0.050000 (OVERFITTING: 6 epochs)
2025-09-30 11:28:26,917 - CIFAR-10_Training - INFO - Starting Epoch 20/100
2025-09-30 11:29:09,845 - CIFAR-10_Training - INFO - Epoch 20: Train Loss: 0.0297, Train Acc: 99.12%, Test Loss: 0.8981, Test Acc: 79.87%, Acc Diff: 19.25%, LR: 0.050000 (OVERFITTING: 7 epochs)
2025-09-30 11:29:09,845 - CIFAR-10_Training - INFO - Starting Epoch 21/100
2025-09-30 11:29:52,288 - CIFAR-10_Training - INFO - Epoch 21: Train Loss: 0.0293, Train Acc: 99.10%, Test Loss: 0.7969, Test Acc: 82.21%, Acc Diff: 16.89%, LR: 0.050000 (OVERFITTING: 8 epochs)
2025-09-30 11:29:52,288 - CIFAR-10_Training - INFO - Starting Epoch 22/100
2025-09-30 11:30:35,049 - CIFAR-10_Training - INFO - Epoch 22: Train Loss: 0.0236, Train Acc: 99.30%, Test Loss: 0.8961, Test Acc: 81.01%, Acc Diff: 18.29%, LR: 0.050000 (OVERFITTING: 9 epochs)
2025-09-30 11:30:35,049 - CIFAR-10_Training - INFO - Starting Epoch 23/100
2025-09-30 11:31:17,820 - CIFAR-10_Training - INFO - Epoch 23: Train Loss: 0.0252, Train Acc: 99.24%, Test Loss: 0.7952, Test Acc: 82.34%, Acc Diff: 16.90%, LR: 0.050000 (OVERFITTING: 10 epochs)
2025-09-30 11:31:17,820 - CIFAR-10_Training - WARNING - ============================================================
2025-09-30 11:31:17,820 - CIFAR-10_Training - WARNING - EARLY STOPPING TRIGGERED!
2025-09-30 11:31:17,820 - CIFAR-10_Training - WARNING - ============================================================
2025-09-30 11:31:17,828 - CIFAR-10_Training - WARNING - Training stopped due to overfitting.
2025-09-30 11:31:17,828 - CIFAR-10_Training - WARNING - Train accuracy - Test accuracy = 16.90%
2025-09-30 11:31:17,828 - CIFAR-10_Training - WARNING - Overfitting threshold: 15.0%
2025-09-30 11:31:17,828 - CIFAR-10_Training - WARNING - Consecutive overfitting epochs: 10
2025-09-30 11:31:17,828 - CIFAR-10_Training - WARNING - Patience: 10 epochs
2025-09-30 11:31:17,828 - CIFAR-10_Training - WARNING - ============================================================
2025-09-30 11:31:17,828 - CIFAR-10_Training - INFO - Training completed!
2025-09-30 11:31:17,828 - CIFAR-10_Training - INFO - Final Results: {'final_train_loss': 0.025195614016633863, 'final_test_loss': 0.7951912139892579, 'final_train_accuracy': 99.242, 'final_test_accuracy': 82.34, 'best_test_accuracy': 82.82, 'final_accuracy_difference': 16.902, 'max_accuracy_difference': 21.848, 'avg_accuracy_difference': 14.557391304347828, 'overfitting_epochs': 10, 'stopped_due_to_overfitting': True}
2025-09-30 11:31:17,828 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:31:17,828 - CIFAR-10_Training - INFO - OVERFITTING ANALYSIS
2025-09-30 11:31:17,828 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:31:17,844 - CIFAR-10_Training - INFO - Final accuracy difference: 16.90%
2025-09-30 11:31:17,844 - CIFAR-10_Training - INFO - Maximum accuracy difference: 21.85%
2025-09-30 11:31:17,844 - CIFAR-10_Training - INFO - Average accuracy difference: 14.56%
2025-09-30 11:31:17,860 - CIFAR-10_Training - INFO - Consecutive overfitting epochs: 10
2025-09-30 11:31:17,860 - CIFAR-10_Training - INFO - Stopped due to overfitting: True
2025-09-30 11:31:17,860 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:31:19,945 - CIFAR-10_Training - INFO - Training curves saved to: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Setup\logs\training_curves_20250930_113117.png
2025-09-30 11:32:17,043 - CIFAR-10_Training - INFO - Model saved to: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Setup\models\cifar10_model_20250930_113216.pth
2025-09-30 11:32:17,044 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:32:17,044 - CIFAR-10_Training - INFO - TRAINING PIPELINE COMPLETED SUCCESSFULLY
2025-09-30 11:32:17,045 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 11:32:17,045 - CIFAR-10_Training - INFO - Final Metrics: {'final_train_loss': 0.025195614016633863, 'final_test_loss': 0.7951912139892579, 'final_train_accuracy': 99.242, 'final_test_accuracy': 82.34, 'best_test_accuracy': 82.82, 'final_accuracy_difference': 16.902, 'max_accuracy_difference': 21.848, 'avg_accuracy_difference': 14.557391304347828, 'overfitting_epochs': 10, 'stopped_due_to_overfitting': True}
