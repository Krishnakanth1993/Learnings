2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs\20251001_154909_cifar10_training.log
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - Updated Configuration (from main()):
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Epochs: 200
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Optimizer: SGD
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Scheduler: StepLR
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Step Size: 30
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Batch Size: 128
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Num Workers: 4
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Pin Memory: True
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Shuffle: True
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Dropout Rate: 0.05
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Device: CUDA
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\models
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Save Model: True
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO -   - Log Level: DEBUG
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - CIFAR-10 TRAINING EXPERIMENT STARTED
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=128, num_workers=4, pin_memory=True, shuffle=True, mean=(0.1307,), std=(0.3081,), cifar10_mean=(0.4914, 0.4822, 0.4465), cifar10_std=(0.247, 0.2435, 0.2616), rotation_range=(-7.0, 7.0), fill_value=1)
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - Model Config: ModelConfig(input_channels=1, input_size=(28, 28), num_classes=10, dropout_rate=0.05)
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - Training Config: TrainingConfig(epochs=200, learning_rate=0.05, momentum=0.9, weight_decay=0.0, scheduler_step_size=30, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='StepLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001)
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - Setting up data...
2025-10-01 15:49:09,580 - CIFAR-10_Training - INFO - Loading CIFAR-10 dataset...
2025-10-01 15:49:11,118 - CIFAR-10_Training - INFO - CIFAR-10 dataset loaded successfully!
2025-10-01 15:49:11,118 - CIFAR-10_Training - INFO - Train samples: 50000
2025-10-01 15:49:11,118 - CIFAR-10_Training - INFO - Test samples: 10000
2025-10-01 15:49:11,118 - CIFAR-10_Training - INFO - Computing CIFAR-10 data statistics...
2025-10-01 15:49:13,520 - CIFAR-10_Training - INFO - CIFAR-10 Data Statistics:
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO -   - Size: 153,600,000
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO -   - Min: 0.0000
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO -   - Max: 1.0000
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO -   - Mean: 0.4734
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO -   - Std: 0.2516
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO -   - Variance: 0.0633
2025-10-01 15:49:13,524 - CIFAR-10_Training - INFO - Channel-wise Statistics:
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -   Red Channel:
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Mean: 0.4914
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Std: 0.2470
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -   Green Channel:
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Mean: 0.4822
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Std: 0.2435
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -   Blue Channel:
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Mean: 0.4465
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Std: 0.2616
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-10-01 15:49:13,526 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-10-01 15:49:31,242 - CIFAR-10_Training - ERROR - Training pipeline failed: Caught KeyError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\.venv\Lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\.venv\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\.venv\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\.venv\Lib\site-packages\torchvision\datasets\cifar.py", line 119, in __getitem__
    img = self.transform(img)
          ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\.venv\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\.venv\Lib\site-packages\albumentations\core\transforms_interface.py", line 246, in __call__
    raise KeyError(msg)
KeyError: 'You have to pass data to augmentations as named arguments, for example: aug(image=image)'

