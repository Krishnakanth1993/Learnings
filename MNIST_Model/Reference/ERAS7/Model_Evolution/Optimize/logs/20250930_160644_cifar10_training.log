2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs\20250930_160644_cifar10_training.log
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - Updated Configuration (from main()):
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Epochs: 50
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Optimizer: SGD
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Scheduler: StepLR
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Step Size: 20
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Batch Size: 128
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Num Workers: 4
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Pin Memory: True
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Shuffle: True
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Dropout Rate: 0.05
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Device: CUDA
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\models
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Save Model: True
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO -   - Log Level: DEBUG
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - CIFAR-10 TRAINING EXPERIMENT STARTED
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=128, num_workers=4, pin_memory=True, shuffle=True, mean=(0.1307,), std=(0.3081,), cifar10_mean=(0.4914, 0.4822, 0.4465), cifar10_std=(0.247, 0.2435, 0.2616), rotation_range=(-7.0, 7.0), fill_value=1)
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - Model Config: ModelConfig(input_channels=1, input_size=(28, 28), num_classes=10, dropout_rate=0.05)
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - Training Config: TrainingConfig(epochs=50, learning_rate=0.05, momentum=0.9, weight_decay=0.0, scheduler_step_size=20, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='StepLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001)
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - Setting up data...
2025-09-30 16:06:44,037 - CIFAR-10_Training - INFO - Loading CIFAR-10 dataset...
2025-09-30 16:06:45,446 - CIFAR-10_Training - INFO - CIFAR-10 dataset loaded successfully!
2025-09-30 16:06:45,446 - CIFAR-10_Training - INFO - Train samples: 50000
2025-09-30 16:06:45,446 - CIFAR-10_Training - INFO - Test samples: 10000
2025-09-30 16:06:45,446 - CIFAR-10_Training - INFO - Computing CIFAR-10 data statistics...
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO - CIFAR-10 Data Statistics:
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   - Size: 153,600,000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   - Min: 0.0000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   - Max: 1.0000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   - Mean: 0.4734
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   - Std: 0.2516
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   - Variance: 0.0633
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO - Channel-wise Statistics:
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   Red Channel:
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Mean: 0.4914
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Std: 0.2470
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   Green Channel:
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Mean: 0.4822
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Std: 0.2435
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -   Blue Channel:
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Mean: 0.4465
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Std: 0.2616
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 16:06:47,165 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 16:07:00,380 - CIFAR-10_Training - INFO - CIFAR-10 Batch Information:
2025-09-30 16:07:00,381 - CIFAR-10_Training - INFO -   - Batch size: 128
2025-09-30 16:07:00,381 - CIFAR-10_Training - INFO -   - Image shape: torch.Size([3, 32, 32])
2025-09-30 16:07:00,381 - CIFAR-10_Training - INFO -   - Label shape: torch.Size([128])
2025-09-30 16:07:00,381 - CIFAR-10_Training - INFO -   - Data type: torch.float32
2025-09-30 16:07:00,381 - CIFAR-10_Training - INFO -   - Number of classes: 10
2025-09-30 16:07:01,750 - CIFAR-10_Training - INFO - Getting input size from CIFAR-10 data loader...
2025-09-30 16:07:13,991 - CIFAR-10_Training - INFO - CIFAR-10 input size from data loader: (3, 32, 32)
2025-09-30 16:07:15,020 - CIFAR-10_Training - INFO - Setting up model...
2025-09-30 16:07:15,042 - CIFAR-10_Training - INFO - Generating model summary...
2025-09-30 16:07:15,584 - CIFAR-10_Training - INFO - Model Architecture Summary:
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -   - Total Parameters: 217,816
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -   - Batch Normalization: Yes
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -   - Dropout: No
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -   - GAP Layers: No
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -   - FC Layers: Yes
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - DETAILED MODEL ARCHITECTURE SUMMARY
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Layer (type)               Output Shape         Param #
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - ================================================================
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -             Conv2d-1            [-1, 8, 32, 32]             216
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -        BatchNorm2d-2            [-1, 8, 32, 32]              16
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -               ReLU-3            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -          Dropout2d-4            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -             Conv2d-5            [-1, 8, 32, 32]             576
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -        BatchNorm2d-6            [-1, 8, 32, 32]              16
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -               ReLU-7            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -          Dropout2d-8            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -             Conv2d-9            [-1, 8, 32, 32]             576
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-10            [-1, 8, 32, 32]              16
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-11            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-12            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-13            [-1, 8, 32, 32]             576
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-14            [-1, 8, 32, 32]              16
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-15            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-16            [-1, 8, 32, 32]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         MaxPool2d-17            [-1, 8, 16, 16]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-18           [-1, 32, 16, 16]           2,304
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-19           [-1, 32, 16, 16]              64
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-20           [-1, 32, 16, 16]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-21           [-1, 32, 16, 16]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-22           [-1, 32, 16, 16]           9,216
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-23           [-1, 32, 16, 16]              64
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-24           [-1, 32, 16, 16]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-25           [-1, 32, 16, 16]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-26           [-1, 32, 16, 16]           9,216
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-27           [-1, 32, 16, 16]              64
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-28           [-1, 32, 16, 16]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-29           [-1, 32, 16, 16]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         MaxPool2d-30             [-1, 32, 8, 8]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-31             [-1, 32, 8, 8]           9,216
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-32             [-1, 32, 8, 8]              64
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-33             [-1, 32, 8, 8]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-34             [-1, 32, 8, 8]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-35             [-1, 32, 8, 8]           9,216
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-36             [-1, 32, 8, 8]              64
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-37             [-1, 32, 8, 8]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-38             [-1, 32, 8, 8]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-39             [-1, 32, 8, 8]           9,216
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-40             [-1, 32, 8, 8]              64
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-41             [-1, 32, 8, 8]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-42             [-1, 32, 8, 8]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         MaxPool2d-43             [-1, 32, 4, 4]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-44             [-1, 64, 4, 4]          18,432
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-45             [-1, 64, 4, 4]             128
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-46             [-1, 64, 4, 4]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-47             [-1, 64, 4, 4]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-48            [-1, 128, 4, 4]          73,728
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-49            [-1, 128, 4, 4]             256
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-50            [-1, 128, 4, 4]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-51            [-1, 128, 4, 4]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-52             [-1, 64, 4, 4]          73,728
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -       BatchNorm2d-53             [-1, 64, 4, 4]             128
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -              ReLU-54             [-1, 64, 4, 4]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -         Dropout2d-55             [-1, 64, 4, 4]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO -            Conv2d-56             [-1, 10, 4, 4]             640
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - AdaptiveAvgPool2d-57             [-1, 10, 1, 1]               0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - ================================================================
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - Total params: 217,816
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - Trainable params: 217,816
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - Non-trainable params: 0
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - Input size (MB): 0.01
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - Forward/backward pass size (MB): 2.10
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - Params size (MB): 0.83
2025-09-30 16:07:15,599 - CIFAR-10_Training - INFO - Estimated Total Size (MB): 2.94
2025-09-30 16:07:15,605 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 16:07:15,605 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:07:15,605 - CIFAR-10_Training - INFO - Setting up trainer...
2025-09-30 16:07:15,607 - CIFAR-10_Training - INFO - Using device: cuda
2025-09-30 16:07:15,607 - CIFAR-10_Training - INFO - Early stopping: Stop if train_acc - test_acc > 15.0% for 10 epochs
2025-09-30 16:07:15,607 - CIFAR-10_Training - INFO - Starting training process...
2025-09-30 16:07:15,607 - CIFAR-10_Training - INFO - Starting training process...
2025-09-30 16:07:15,607 - CIFAR-10_Training - INFO - Using optimizer: SGD
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO - Using scheduler: StepLR
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO - Optimizer Configuration:
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO - Scheduler Configuration:
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO -   - Step Size: 20
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-09-30 16:07:15,608 - CIFAR-10_Training - INFO - Starting Epoch 1/50
2025-09-30 16:07:45,784 - CIFAR-10_Training - INFO - Epoch  1: Train Loss: 1.7941, Train Acc: 32.28%, Test Loss: 1.5217, Test Acc: 42.17%, Acc Diff: -9.89%, LR: 0.050000
2025-09-30 16:07:45,784 - CIFAR-10_Training - INFO - Starting Epoch 2/50
2025-09-30 16:08:15,137 - CIFAR-10_Training - INFO - Epoch  2: Train Loss: 1.4641, Train Acc: 46.17%, Test Loss: 1.2609, Test Acc: 53.48%, Acc Diff: -7.31%, LR: 0.050000
2025-09-30 16:08:15,138 - CIFAR-10_Training - INFO - Starting Epoch 3/50
2025-09-30 16:08:44,376 - CIFAR-10_Training - INFO - Epoch  3: Train Loss: 1.2508, Train Acc: 54.98%, Test Loss: 1.1476, Test Acc: 58.78%, Acc Diff: -3.80%, LR: 0.050000
2025-09-30 16:08:44,376 - CIFAR-10_Training - INFO - Starting Epoch 4/50
2025-09-30 16:09:17,458 - CIFAR-10_Training - INFO - Epoch  4: Train Loss: 1.0959, Train Acc: 61.01%, Test Loss: 0.9629, Test Acc: 66.43%, Acc Diff: -5.42%, LR: 0.050000
2025-09-30 16:09:17,459 - CIFAR-10_Training - INFO - Starting Epoch 5/50
2025-09-30 16:09:54,869 - CIFAR-10_Training - INFO - Epoch  5: Train Loss: 0.9955, Train Acc: 65.32%, Test Loss: 0.8702, Test Acc: 69.91%, Acc Diff: -4.59%, LR: 0.050000
2025-09-30 16:09:54,869 - CIFAR-10_Training - INFO - Starting Epoch 6/50
2025-09-30 16:10:27,839 - CIFAR-10_Training - INFO - Epoch  6: Train Loss: 0.9247, Train Acc: 67.59%, Test Loss: 0.8047, Test Acc: 72.07%, Acc Diff: -4.48%, LR: 0.050000
2025-09-30 16:10:27,839 - CIFAR-10_Training - INFO - Starting Epoch 7/50
2025-09-30 16:11:01,761 - CIFAR-10_Training - INFO - Epoch  7: Train Loss: 0.8640, Train Acc: 70.04%, Test Loss: 0.7766, Test Acc: 72.91%, Acc Diff: -2.87%, LR: 0.050000
2025-09-30 16:11:01,761 - CIFAR-10_Training - INFO - Starting Epoch 8/50
2025-09-30 16:11:34,727 - CIFAR-10_Training - INFO - Epoch  8: Train Loss: 0.8260, Train Acc: 71.34%, Test Loss: 0.7379, Test Acc: 74.14%, Acc Diff: -2.80%, LR: 0.050000
2025-09-30 16:11:34,727 - CIFAR-10_Training - INFO - Starting Epoch 9/50
2025-09-30 16:12:05,964 - CIFAR-10_Training - INFO - Epoch  9: Train Loss: 0.7929, Train Acc: 72.30%, Test Loss: 0.7199, Test Acc: 75.24%, Acc Diff: -2.94%, LR: 0.050000
2025-09-30 16:12:05,964 - CIFAR-10_Training - INFO - Starting Epoch 10/50
2025-09-30 16:12:34,763 - CIFAR-10_Training - INFO - Epoch 10: Train Loss: 0.7572, Train Acc: 73.82%, Test Loss: 0.7077, Test Acc: 75.22%, Acc Diff: -1.40%, LR: 0.050000
2025-09-30 16:12:34,763 - CIFAR-10_Training - INFO - Starting Epoch 11/50
2025-09-30 16:13:06,860 - CIFAR-10_Training - INFO - Epoch 11: Train Loss: 0.7300, Train Acc: 74.72%, Test Loss: 0.7061, Test Acc: 75.81%, Acc Diff: -1.09%, LR: 0.050000
2025-09-30 16:13:06,862 - CIFAR-10_Training - INFO - Starting Epoch 12/50
2025-09-30 16:13:55,758 - CIFAR-10_Training - INFO - Epoch 12: Train Loss: 0.7095, Train Acc: 75.19%, Test Loss: 0.6892, Test Acc: 76.70%, Acc Diff: -1.51%, LR: 0.050000
2025-09-30 16:13:55,759 - CIFAR-10_Training - INFO - Starting Epoch 13/50
2025-09-30 16:14:46,702 - CIFAR-10_Training - INFO - Epoch 13: Train Loss: 0.6918, Train Acc: 75.98%, Test Loss: 0.6657, Test Acc: 76.99%, Acc Diff: -1.01%, LR: 0.050000
2025-09-30 16:14:46,702 - CIFAR-10_Training - INFO - Starting Epoch 14/50
2025-09-30 16:15:36,777 - CIFAR-10_Training - INFO - Epoch 14: Train Loss: 0.6670, Train Acc: 76.77%, Test Loss: 0.6558, Test Acc: 77.58%, Acc Diff: -0.81%, LR: 0.050000
2025-09-30 16:15:36,777 - CIFAR-10_Training - INFO - Starting Epoch 15/50
2025-09-30 16:16:19,133 - CIFAR-10_Training - INFO - Epoch 15: Train Loss: 0.6485, Train Acc: 77.46%, Test Loss: 0.6746, Test Acc: 76.86%, Acc Diff: 0.60%, LR: 0.050000
2025-09-30 16:16:19,133 - CIFAR-10_Training - INFO - Starting Epoch 16/50
2025-09-30 16:16:48,299 - CIFAR-10_Training - INFO - Epoch 16: Train Loss: 0.6330, Train Acc: 77.69%, Test Loss: 0.6377, Test Acc: 78.06%, Acc Diff: -0.37%, LR: 0.050000
2025-09-30 16:16:48,299 - CIFAR-10_Training - INFO - Starting Epoch 17/50
2025-09-30 16:17:18,560 - CIFAR-10_Training - INFO - Epoch 17: Train Loss: 0.6200, Train Acc: 78.37%, Test Loss: 0.6451, Test Acc: 77.88%, Acc Diff: 0.49%, LR: 0.050000
2025-09-30 16:17:18,560 - CIFAR-10_Training - INFO - Starting Epoch 18/50
2025-09-30 16:17:54,055 - CIFAR-10_Training - INFO - Epoch 18: Train Loss: 0.6067, Train Acc: 78.71%, Test Loss: 0.6386, Test Acc: 78.26%, Acc Diff: 0.45%, LR: 0.050000
2025-09-30 16:17:54,055 - CIFAR-10_Training - INFO - Starting Epoch 19/50
2025-09-30 16:18:23,692 - CIFAR-10_Training - INFO - Epoch 19: Train Loss: 0.5907, Train Acc: 79.28%, Test Loss: 0.6363, Test Acc: 78.18%, Acc Diff: 1.10%, LR: 0.050000
2025-09-30 16:18:23,692 - CIFAR-10_Training - INFO - Starting Epoch 20/50
2025-09-30 16:18:52,525 - CIFAR-10_Training - INFO - Epoch 20: Train Loss: 0.5783, Train Acc: 79.61%, Test Loss: 0.6546, Test Acc: 77.68%, Acc Diff: 1.93%, LR: 0.005000
2025-09-30 16:18:52,525 - CIFAR-10_Training - INFO - Starting Epoch 21/50
2025-09-30 16:19:21,687 - CIFAR-10_Training - INFO - Epoch 21: Train Loss: 0.5138, Train Acc: 82.14%, Test Loss: 0.5914, Test Acc: 79.99%, Acc Diff: 2.15%, LR: 0.005000
2025-09-30 16:19:21,687 - CIFAR-10_Training - INFO - Starting Epoch 22/50
2025-09-30 16:19:53,021 - CIFAR-10_Training - INFO - Epoch 22: Train Loss: 0.4851, Train Acc: 83.00%, Test Loss: 0.5861, Test Acc: 80.37%, Acc Diff: 2.63%, LR: 0.005000
2025-09-30 16:19:53,021 - CIFAR-10_Training - INFO - Starting Epoch 23/50
2025-09-30 16:20:23,328 - CIFAR-10_Training - INFO - Epoch 23: Train Loss: 0.4785, Train Acc: 83.29%, Test Loss: 0.5860, Test Acc: 80.23%, Acc Diff: 3.06%, LR: 0.005000
2025-09-30 16:20:23,328 - CIFAR-10_Training - INFO - Starting Epoch 24/50
2025-09-30 16:20:57,273 - CIFAR-10_Training - INFO - Epoch 24: Train Loss: 0.4670, Train Acc: 83.90%, Test Loss: 0.5862, Test Acc: 80.44%, Acc Diff: 3.46%, LR: 0.005000
2025-09-30 16:20:57,273 - CIFAR-10_Training - INFO - Starting Epoch 25/50
2025-09-30 16:21:27,205 - CIFAR-10_Training - INFO - Epoch 25: Train Loss: 0.4607, Train Acc: 83.88%, Test Loss: 0.5882, Test Acc: 80.50%, Acc Diff: 3.38%, LR: 0.005000
2025-09-30 16:21:27,205 - CIFAR-10_Training - INFO - Starting Epoch 26/50
2025-09-30 16:21:55,437 - CIFAR-10_Training - INFO - Epoch 26: Train Loss: 0.4578, Train Acc: 84.01%, Test Loss: 0.5876, Test Acc: 80.33%, Acc Diff: 3.68%, LR: 0.005000
2025-09-30 16:21:55,437 - CIFAR-10_Training - INFO - Starting Epoch 27/50
2025-09-30 16:22:43,307 - CIFAR-10_Training - INFO - Epoch 27: Train Loss: 0.4547, Train Acc: 84.10%, Test Loss: 0.5902, Test Acc: 80.48%, Acc Diff: 3.62%, LR: 0.005000
2025-09-30 16:22:43,308 - CIFAR-10_Training - INFO - Starting Epoch 28/50
2025-09-30 16:23:33,612 - CIFAR-10_Training - INFO - Epoch 28: Train Loss: 0.4458, Train Acc: 84.34%, Test Loss: 0.5916, Test Acc: 80.21%, Acc Diff: 4.13%, LR: 0.005000
2025-09-30 16:23:33,612 - CIFAR-10_Training - INFO - Starting Epoch 29/50
2025-09-30 16:24:02,324 - CIFAR-10_Training - INFO - Epoch 29: Train Loss: 0.4456, Train Acc: 84.33%, Test Loss: 0.5900, Test Acc: 80.35%, Acc Diff: 3.98%, LR: 0.005000
2025-09-30 16:24:02,324 - CIFAR-10_Training - INFO - Starting Epoch 30/50
2025-09-30 16:24:31,757 - CIFAR-10_Training - INFO - Epoch 30: Train Loss: 0.4423, Train Acc: 84.42%, Test Loss: 0.5915, Test Acc: 80.40%, Acc Diff: 4.02%, LR: 0.005000
2025-09-30 16:24:31,757 - CIFAR-10_Training - INFO - Starting Epoch 31/50
2025-09-30 16:25:01,593 - CIFAR-10_Training - INFO - Epoch 31: Train Loss: 0.4381, Train Acc: 84.66%, Test Loss: 0.5948, Test Acc: 80.09%, Acc Diff: 4.57%, LR: 0.005000
2025-09-30 16:25:01,593 - CIFAR-10_Training - INFO - Starting Epoch 32/50
2025-09-30 16:25:33,153 - CIFAR-10_Training - INFO - Epoch 32: Train Loss: 0.4315, Train Acc: 84.83%, Test Loss: 0.5959, Test Acc: 80.44%, Acc Diff: 4.39%, LR: 0.005000
2025-09-30 16:25:33,153 - CIFAR-10_Training - INFO - Starting Epoch 33/50
2025-09-30 16:26:04,292 - CIFAR-10_Training - INFO - Epoch 33: Train Loss: 0.4303, Train Acc: 84.74%, Test Loss: 0.5939, Test Acc: 80.36%, Acc Diff: 4.38%, LR: 0.005000
2025-09-30 16:26:04,292 - CIFAR-10_Training - INFO - Starting Epoch 34/50
2025-09-30 16:26:35,369 - CIFAR-10_Training - INFO - Epoch 34: Train Loss: 0.4294, Train Acc: 84.84%, Test Loss: 0.5977, Test Acc: 80.33%, Acc Diff: 4.51%, LR: 0.005000
2025-09-30 16:26:35,369 - CIFAR-10_Training - INFO - Starting Epoch 35/50
2025-09-30 16:27:08,135 - CIFAR-10_Training - INFO - Epoch 35: Train Loss: 0.4230, Train Acc: 85.15%, Test Loss: 0.5996, Test Acc: 80.30%, Acc Diff: 4.85%, LR: 0.005000
2025-09-30 16:27:08,135 - CIFAR-10_Training - INFO - Starting Epoch 36/50
2025-09-30 16:27:39,705 - CIFAR-10_Training - INFO - Epoch 36: Train Loss: 0.4197, Train Acc: 85.11%, Test Loss: 0.5972, Test Acc: 80.11%, Acc Diff: 5.00%, LR: 0.005000
2025-09-30 16:27:39,705 - CIFAR-10_Training - INFO - Starting Epoch 37/50
2025-09-30 16:28:10,251 - CIFAR-10_Training - INFO - Epoch 37: Train Loss: 0.4201, Train Acc: 85.30%, Test Loss: 0.5985, Test Acc: 80.27%, Acc Diff: 5.03%, LR: 0.005000
2025-09-30 16:28:10,251 - CIFAR-10_Training - INFO - Starting Epoch 38/50
2025-09-30 16:28:40,613 - CIFAR-10_Training - INFO - Epoch 38: Train Loss: 0.4198, Train Acc: 85.44%, Test Loss: 0.5984, Test Acc: 80.29%, Acc Diff: 5.15%, LR: 0.005000
2025-09-30 16:28:40,613 - CIFAR-10_Training - INFO - Starting Epoch 39/50
2025-09-30 16:29:11,180 - CIFAR-10_Training - INFO - Epoch 39: Train Loss: 0.4112, Train Acc: 85.50%, Test Loss: 0.6037, Test Acc: 80.54%, Acc Diff: 4.96%, LR: 0.005000
2025-09-30 16:29:11,180 - CIFAR-10_Training - INFO - Starting Epoch 40/50
2025-09-30 16:29:40,651 - CIFAR-10_Training - INFO - Epoch 40: Train Loss: 0.4106, Train Acc: 85.49%, Test Loss: 0.6048, Test Acc: 80.36%, Acc Diff: 5.13%, LR: 0.000500
2025-09-30 16:29:40,651 - CIFAR-10_Training - INFO - Starting Epoch 41/50
2025-09-30 16:30:08,983 - CIFAR-10_Training - INFO - Epoch 41: Train Loss: 0.4019, Train Acc: 85.81%, Test Loss: 0.5990, Test Acc: 80.42%, Acc Diff: 5.39%, LR: 0.000500
2025-09-30 16:30:08,983 - CIFAR-10_Training - INFO - Starting Epoch 42/50
2025-09-30 16:30:37,886 - CIFAR-10_Training - INFO - Epoch 42: Train Loss: 0.4016, Train Acc: 85.86%, Test Loss: 0.5988, Test Acc: 80.37%, Acc Diff: 5.49%, LR: 0.000500
2025-09-30 16:30:37,887 - CIFAR-10_Training - INFO - Starting Epoch 43/50
2025-09-30 16:31:24,123 - CIFAR-10_Training - INFO - Epoch 43: Train Loss: 0.4025, Train Acc: 85.86%, Test Loss: 0.5997, Test Acc: 80.48%, Acc Diff: 5.38%, LR: 0.000500
2025-09-30 16:31:24,123 - CIFAR-10_Training - INFO - Starting Epoch 44/50
2025-09-30 16:32:03,912 - CIFAR-10_Training - INFO - Epoch 44: Train Loss: 0.3971, Train Acc: 85.99%, Test Loss: 0.6016, Test Acc: 80.47%, Acc Diff: 5.52%, LR: 0.000500
2025-09-30 16:32:03,912 - CIFAR-10_Training - INFO - Starting Epoch 45/50
2025-09-30 16:32:34,470 - CIFAR-10_Training - INFO - Epoch 45: Train Loss: 0.3989, Train Acc: 85.88%, Test Loss: 0.6012, Test Acc: 80.39%, Acc Diff: 5.49%, LR: 0.000500
2025-09-30 16:32:34,471 - CIFAR-10_Training - INFO - Starting Epoch 46/50
2025-09-30 16:33:23,433 - CIFAR-10_Training - INFO - Epoch 46: Train Loss: 0.3948, Train Acc: 86.07%, Test Loss: 0.5978, Test Acc: 80.40%, Acc Diff: 5.67%, LR: 0.000500
2025-09-30 16:33:23,434 - CIFAR-10_Training - INFO - Starting Epoch 47/50
2025-09-30 16:34:00,391 - CIFAR-10_Training - INFO - Epoch 47: Train Loss: 0.3942, Train Acc: 86.03%, Test Loss: 0.6040, Test Acc: 80.53%, Acc Diff: 5.50%, LR: 0.000500
2025-09-30 16:34:00,391 - CIFAR-10_Training - INFO - Starting Epoch 48/50
2025-09-30 16:34:30,120 - CIFAR-10_Training - INFO - Epoch 48: Train Loss: 0.3951, Train Acc: 85.88%, Test Loss: 0.6028, Test Acc: 80.53%, Acc Diff: 5.35%, LR: 0.000500
2025-09-30 16:34:30,120 - CIFAR-10_Training - INFO - Starting Epoch 49/50
2025-09-30 16:34:59,355 - CIFAR-10_Training - INFO - Epoch 49: Train Loss: 0.3895, Train Acc: 86.31%, Test Loss: 0.5990, Test Acc: 80.58%, Acc Diff: 5.73%, LR: 0.000500
2025-09-30 16:34:59,355 - CIFAR-10_Training - INFO - Starting Epoch 50/50
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - Epoch 50: Train Loss: 0.3913, Train Acc: 86.25%, Test Loss: 0.5971, Test Acc: 80.64%, Acc Diff: 5.61%, LR: 0.000500
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - Training completed!
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - Final Results: {'final_train_loss': 0.3912702766830659, 'final_test_loss': 0.5971465232849121, 'final_train_accuracy': 86.246, 'final_test_accuracy': 80.64, 'best_test_accuracy': 80.64, 'final_accuracy_difference': 5.6059999999999945, 'max_accuracy_difference': 5.725999999999999, 'avg_accuracy_difference': 1.8294399999999993, 'overfitting_epochs': 0, 'stopped_due_to_overfitting': False}
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - OVERFITTING ANALYSIS
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - Final accuracy difference: 5.61%
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - Maximum accuracy difference: 5.73%
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - Average accuracy difference: 1.83%
2025-09-30 16:35:31,356 - CIFAR-10_Training - INFO - Consecutive overfitting epochs: 0
2025-09-30 16:35:31,366 - CIFAR-10_Training - INFO - Stopped due to overfitting: False
2025-09-30 16:35:31,366 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:35:32,218 - CIFAR-10_Training - INFO - Training curves saved to: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs\training_curves_20250930_163531.png
2025-09-30 16:35:39,508 - CIFAR-10_Training - INFO - Model saved to: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\models\cifar10_model_20250930_163539.pth
2025-09-30 16:35:39,508 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:35:39,509 - CIFAR-10_Training - INFO - TRAINING PIPELINE COMPLETED SUCCESSFULLY
2025-09-30 16:35:39,509 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 16:35:39,510 - CIFAR-10_Training - INFO - Final Metrics: {'final_train_loss': 0.3912702766830659, 'final_test_loss': 0.5971465232849121, 'final_train_accuracy': 86.246, 'final_test_accuracy': 80.64, 'best_test_accuracy': 80.64, 'final_accuracy_difference': 5.6059999999999945, 'max_accuracy_difference': 5.725999999999999, 'avg_accuracy_difference': 1.8294399999999993, 'overfitting_epochs': 0, 'stopped_due_to_overfitting': False}
