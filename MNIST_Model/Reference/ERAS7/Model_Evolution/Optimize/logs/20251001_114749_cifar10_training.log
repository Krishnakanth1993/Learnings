2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs\20251001_114749_cifar10_training.log
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - Updated Configuration (from main()):
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Epochs: 200
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Optimizer: SGD
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Scheduler: StepLR
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Step Size: 50
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Batch Size: 128
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Num Workers: 4
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Pin Memory: True
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Shuffle: True
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Dropout Rate: 0.05
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Device: CUDA
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\models
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Save Model: True
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO -   - Log Level: DEBUG
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - CIFAR-10 TRAINING EXPERIMENT STARTED
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=128, num_workers=4, pin_memory=True, shuffle=True, mean=(0.1307,), std=(0.3081,), cifar10_mean=(0.4914, 0.4822, 0.4465), cifar10_std=(0.247, 0.2435, 0.2616), rotation_range=(-7.0, 7.0), fill_value=1)
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - Model Config: ModelConfig(input_channels=1, input_size=(28, 28), num_classes=10, dropout_rate=0.05)
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - Training Config: TrainingConfig(epochs=200, learning_rate=0.05, momentum=0.9, weight_decay=0.0, scheduler_step_size=50, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='StepLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001)
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - Setting up data...
2025-10-01 11:47:49,383 - CIFAR-10_Training - INFO - Loading CIFAR-10 dataset...
2025-10-01 11:47:50,738 - CIFAR-10_Training - INFO - CIFAR-10 dataset loaded successfully!
2025-10-01 11:47:50,738 - CIFAR-10_Training - INFO - Train samples: 50000
2025-10-01 11:47:50,738 - CIFAR-10_Training - INFO - Test samples: 10000
2025-10-01 11:47:50,738 - CIFAR-10_Training - INFO - Computing CIFAR-10 data statistics...
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO - CIFAR-10 Data Statistics:
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   - Size: 153,600,000
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   - Min: 0.0000
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   - Max: 1.0000
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   - Mean: 0.4734
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   - Std: 0.2516
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   - Variance: 0.0633
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO - Channel-wise Statistics:
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   Red Channel:
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -     - Mean: 0.4914
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -     - Std: 0.2470
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -   Green Channel:
2025-10-01 11:47:52,450 - CIFAR-10_Training - INFO -     - Mean: 0.4822
2025-10-01 11:47:52,461 - CIFAR-10_Training - INFO -     - Std: 0.2435
2025-10-01 11:47:52,462 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-10-01 11:47:52,462 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-10-01 11:47:52,463 - CIFAR-10_Training - INFO -   Blue Channel:
2025-10-01 11:47:52,464 - CIFAR-10_Training - INFO -     - Mean: 0.4465
2025-10-01 11:47:52,464 - CIFAR-10_Training - INFO -     - Std: 0.2616
2025-10-01 11:47:52,464 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-10-01 11:47:52,464 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-10-01 11:48:04,758 - CIFAR-10_Training - INFO - CIFAR-10 Batch Information:
2025-10-01 11:48:04,758 - CIFAR-10_Training - INFO -   - Batch size: 128
2025-10-01 11:48:04,758 - CIFAR-10_Training - INFO -   - Image shape: torch.Size([3, 32, 32])
2025-10-01 11:48:04,758 - CIFAR-10_Training - INFO -   - Label shape: torch.Size([128])
2025-10-01 11:48:04,758 - CIFAR-10_Training - INFO -   - Data type: torch.float32
2025-10-01 11:48:04,758 - CIFAR-10_Training - INFO -   - Number of classes: 10
2025-10-01 11:48:05,688 - CIFAR-10_Training - INFO - Getting input size from CIFAR-10 data loader...
2025-10-01 11:48:16,141 - CIFAR-10_Training - INFO - CIFAR-10 input size from data loader: (3, 32, 32)
2025-10-01 11:48:16,792 - CIFAR-10_Training - INFO - Setting up model...
2025-10-01 11:48:16,821 - CIFAR-10_Training - INFO - Generating model summary...
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO - Model Architecture Summary:
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -   - Total Parameters: 206,038
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -   - Batch Normalization: Yes
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -   - Dropout: No
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -   - GAP Layers: Yes
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -   - FC Layers: Yes
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO - DETAILED MODEL ARCHITECTURE SUMMARY
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -         Layer (type)               Output Shape         Param #
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO - ================================================================
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -             Conv2d-1           [-1, 16, 32, 32]             432
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -        BatchNorm2d-2           [-1, 16, 32, 32]              32
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -               ReLU-3           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -          Dropout2d-4           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -             Conv2d-5           [-1, 16, 32, 32]           2,304
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -        BatchNorm2d-6           [-1, 16, 32, 32]              32
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -               ReLU-7           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -          Dropout2d-8           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -             Conv2d-9           [-1, 16, 32, 32]           2,304
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -       BatchNorm2d-10           [-1, 16, 32, 32]              32
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -              ReLU-11           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -         Dropout2d-12           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -            Conv2d-13           [-1, 16, 32, 32]           2,304
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -       BatchNorm2d-14           [-1, 16, 32, 32]              32
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -              ReLU-15           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -         Dropout2d-16           [-1, 16, 32, 32]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -            Conv2d-17           [-1, 16, 16, 16]           2,320
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -       BatchNorm2d-18           [-1, 16, 16, 16]              32
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -            Conv2d-19           [-1, 32, 16, 16]           4,608
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -       BatchNorm2d-20           [-1, 32, 16, 16]              64
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -              ReLU-21           [-1, 32, 16, 16]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -         Dropout2d-22           [-1, 32, 16, 16]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -            Conv2d-23           [-1, 32, 16, 16]           9,216
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -       BatchNorm2d-24           [-1, 32, 16, 16]              64
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -              ReLU-25           [-1, 32, 16, 16]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -         Dropout2d-26           [-1, 32, 16, 16]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -            Conv2d-27             [-1, 32, 8, 8]           9,248
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -       BatchNorm2d-28             [-1, 32, 8, 8]              64
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -            Conv2d-29             [-1, 32, 8, 8]             320
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -            Conv2d-30             [-1, 64, 8, 8]           2,112
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO - depthwise_separable_conv-31             [-1, 64, 8, 8]               0
2025-10-01 11:48:17,296 - CIFAR-10_Training - INFO -       BatchNorm2d-32             [-1, 64, 8, 8]             128
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -              ReLU-33             [-1, 64, 8, 8]               0
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -         Dropout2d-34             [-1, 64, 8, 8]               0
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -            Conv2d-35             [-1, 64, 8, 8]          36,864
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -       BatchNorm2d-36             [-1, 64, 8, 8]             128
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -              ReLU-37             [-1, 64, 8, 8]               0
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -         Dropout2d-38             [-1, 64, 8, 8]               0
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -            Conv2d-39             [-1, 64, 4, 4]          36,928
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -       BatchNorm2d-40             [-1, 64, 4, 4]             128
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -            Conv2d-41             [-1, 64, 4, 4]          36,864
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -       BatchNorm2d-42             [-1, 64, 4, 4]             128
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -              ReLU-43             [-1, 64, 4, 4]               0
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -         Dropout2d-44             [-1, 64, 4, 4]               0
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -            Conv2d-45             [-1, 64, 4, 4]          36,864
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -       BatchNorm2d-46             [-1, 64, 4, 4]             128
2025-10-01 11:48:17,303 - CIFAR-10_Training - INFO -              ReLU-47             [-1, 64, 4, 4]               0
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -         Dropout2d-48             [-1, 64, 4, 4]               0
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -            Conv2d-49            [-1, 128, 4, 4]           8,192
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -       BatchNorm2d-50            [-1, 128, 4, 4]             256
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -              ReLU-51            [-1, 128, 4, 4]               0
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -         Dropout2d-52            [-1, 128, 4, 4]               0
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -         AvgPool2d-53            [-1, 128, 1, 1]               0
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -            Linear-54                  [-1, 100]          12,900
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO -            Linear-55                   [-1, 10]           1,010
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - ================================================================
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - Total params: 206,038
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - Trainable params: 206,038
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - Non-trainable params: 0
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - Input size (MB): 0.01
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - Forward/backward pass size (MB): 3.03
2025-10-01 11:48:17,306 - CIFAR-10_Training - INFO - Params size (MB): 0.79
2025-10-01 11:48:17,307 - CIFAR-10_Training - INFO - Estimated Total Size (MB): 3.83
2025-10-01 11:48:17,307 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-10-01 11:48:17,307 - CIFAR-10_Training - INFO - ==================================================
2025-10-01 11:48:17,307 - CIFAR-10_Training - INFO - Setting up trainer...
2025-10-01 11:48:17,308 - CIFAR-10_Training - INFO - Using device: cuda
2025-10-01 11:48:17,308 - CIFAR-10_Training - INFO - Early stopping: Stop if train_acc - test_acc > 15.0% for 10 epochs
2025-10-01 11:48:17,308 - CIFAR-10_Training - INFO - Starting training process...
2025-10-01 11:48:17,308 - CIFAR-10_Training - INFO - Starting training process...
2025-10-01 11:48:17,309 - CIFAR-10_Training - INFO - Using optimizer: SGD
2025-10-01 11:48:17,309 - CIFAR-10_Training - INFO - Using scheduler: StepLR
2025-10-01 11:48:17,310 - CIFAR-10_Training - INFO - Optimizer Configuration:
2025-10-01 11:48:17,310 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-10-01 11:48:17,310 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-10-01 11:48:17,311 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-10-01 11:48:17,311 - CIFAR-10_Training - INFO - Scheduler Configuration:
2025-10-01 11:48:17,311 - CIFAR-10_Training - INFO -   - Step Size: 50
2025-10-01 11:48:17,311 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-10-01 11:48:17,311 - CIFAR-10_Training - INFO - Starting Epoch 1/200
2025-10-01 11:48:46,004 - CIFAR-10_Training - INFO - Epoch  1: Train Loss: 1.7874, Train Acc: 32.45%, Test Loss: 1.5039, Test Acc: 43.54%, Acc Diff: -11.09%, LR: 0.050000
2025-10-01 11:48:46,004 - CIFAR-10_Training - INFO - Starting Epoch 2/200
2025-10-01 11:49:14,719 - CIFAR-10_Training - INFO - Epoch  2: Train Loss: 1.4876, Train Acc: 45.91%, Test Loss: 1.3257, Test Acc: 51.44%, Acc Diff: -5.53%, LR: 0.050000
2025-10-01 11:49:14,719 - CIFAR-10_Training - INFO - Starting Epoch 3/200
2025-10-01 11:49:43,300 - CIFAR-10_Training - INFO - Epoch  3: Train Loss: 1.3581, Train Acc: 51.27%, Test Loss: 1.2042, Test Acc: 55.79%, Acc Diff: -4.52%, LR: 0.050000
2025-10-01 11:49:43,300 - CIFAR-10_Training - INFO - Starting Epoch 4/200
2025-10-01 11:50:11,746 - CIFAR-10_Training - INFO - Epoch  4: Train Loss: 1.2615, Train Acc: 54.91%, Test Loss: 1.1289, Test Acc: 60.05%, Acc Diff: -5.14%, LR: 0.050000
2025-10-01 11:50:11,746 - CIFAR-10_Training - INFO - Starting Epoch 5/200
2025-10-01 11:50:40,319 - CIFAR-10_Training - INFO - Epoch  5: Train Loss: 1.2027, Train Acc: 57.25%, Test Loss: 1.0505, Test Acc: 62.25%, Acc Diff: -5.00%, LR: 0.050000
2025-10-01 11:50:40,319 - CIFAR-10_Training - INFO - Starting Epoch 6/200
2025-10-01 11:51:08,565 - CIFAR-10_Training - INFO - Epoch  6: Train Loss: 1.1509, Train Acc: 59.43%, Test Loss: 1.0334, Test Acc: 63.43%, Acc Diff: -4.00%, LR: 0.050000
2025-10-01 11:51:08,565 - CIFAR-10_Training - INFO - Starting Epoch 7/200
2025-10-01 11:51:37,676 - CIFAR-10_Training - INFO - Epoch  7: Train Loss: 1.1161, Train Acc: 60.67%, Test Loss: 0.9956, Test Acc: 65.31%, Acc Diff: -4.64%, LR: 0.050000
2025-10-01 11:51:37,676 - CIFAR-10_Training - INFO - Starting Epoch 8/200
2025-10-01 11:52:05,864 - CIFAR-10_Training - INFO - Epoch  8: Train Loss: 1.0819, Train Acc: 61.80%, Test Loss: 0.9658, Test Acc: 65.69%, Acc Diff: -3.89%, LR: 0.050000
2025-10-01 11:52:05,864 - CIFAR-10_Training - INFO - Starting Epoch 9/200
2025-10-01 11:52:34,308 - CIFAR-10_Training - INFO - Epoch  9: Train Loss: 1.0553, Train Acc: 62.79%, Test Loss: 0.9357, Test Acc: 66.65%, Acc Diff: -3.86%, LR: 0.050000
2025-10-01 11:52:34,308 - CIFAR-10_Training - INFO - Starting Epoch 10/200
2025-10-01 11:53:02,937 - CIFAR-10_Training - INFO - Epoch 10: Train Loss: 1.0321, Train Acc: 63.84%, Test Loss: 0.9113, Test Acc: 67.98%, Acc Diff: -4.14%, LR: 0.050000
2025-10-01 11:53:02,937 - CIFAR-10_Training - INFO - Starting Epoch 11/200
2025-10-01 11:53:31,268 - CIFAR-10_Training - INFO - Epoch 11: Train Loss: 1.0090, Train Acc: 64.58%, Test Loss: 0.9168, Test Acc: 67.64%, Acc Diff: -3.06%, LR: 0.050000
2025-10-01 11:53:31,268 - CIFAR-10_Training - INFO - Starting Epoch 12/200
2025-10-01 11:53:59,692 - CIFAR-10_Training - INFO - Epoch 12: Train Loss: 0.9838, Train Acc: 65.41%, Test Loss: 0.9076, Test Acc: 68.02%, Acc Diff: -2.61%, LR: 0.050000
2025-10-01 11:53:59,692 - CIFAR-10_Training - INFO - Starting Epoch 13/200
2025-10-01 11:54:28,289 - CIFAR-10_Training - INFO - Epoch 13: Train Loss: 0.9725, Train Acc: 66.05%, Test Loss: 0.8791, Test Acc: 69.23%, Acc Diff: -3.18%, LR: 0.050000
2025-10-01 11:54:28,289 - CIFAR-10_Training - INFO - Starting Epoch 14/200
2025-10-01 11:54:56,912 - CIFAR-10_Training - INFO - Epoch 14: Train Loss: 0.9519, Train Acc: 66.74%, Test Loss: 0.8620, Test Acc: 69.80%, Acc Diff: -3.06%, LR: 0.050000
2025-10-01 11:54:56,912 - CIFAR-10_Training - INFO - Starting Epoch 15/200
2025-10-01 11:55:25,234 - CIFAR-10_Training - INFO - Epoch 15: Train Loss: 0.9382, Train Acc: 66.96%, Test Loss: 0.8341, Test Acc: 70.87%, Acc Diff: -3.91%, LR: 0.050000
2025-10-01 11:55:25,234 - CIFAR-10_Training - INFO - Starting Epoch 16/200
2025-10-01 11:55:53,382 - CIFAR-10_Training - INFO - Epoch 16: Train Loss: 0.9276, Train Acc: 67.39%, Test Loss: 0.8354, Test Acc: 71.14%, Acc Diff: -3.75%, LR: 0.050000
2025-10-01 11:55:53,382 - CIFAR-10_Training - INFO - Starting Epoch 17/200
2025-10-01 11:56:22,385 - CIFAR-10_Training - INFO - Epoch 17: Train Loss: 0.9151, Train Acc: 68.03%, Test Loss: 0.8302, Test Acc: 71.36%, Acc Diff: -3.33%, LR: 0.050000
2025-10-01 11:56:22,385 - CIFAR-10_Training - INFO - Starting Epoch 18/200
2025-10-01 11:56:50,796 - CIFAR-10_Training - INFO - Epoch 18: Train Loss: 0.9064, Train Acc: 68.29%, Test Loss: 0.8291, Test Acc: 71.26%, Acc Diff: -2.97%, LR: 0.050000
2025-10-01 11:56:50,796 - CIFAR-10_Training - INFO - Starting Epoch 19/200
2025-10-01 11:57:19,217 - CIFAR-10_Training - INFO - Epoch 19: Train Loss: 0.8925, Train Acc: 68.83%, Test Loss: 0.8105, Test Acc: 71.68%, Acc Diff: -2.85%, LR: 0.050000
2025-10-01 11:57:19,217 - CIFAR-10_Training - INFO - Starting Epoch 20/200
2025-10-01 11:57:47,644 - CIFAR-10_Training - INFO - Epoch 20: Train Loss: 0.8824, Train Acc: 69.18%, Test Loss: 0.8129, Test Acc: 71.26%, Acc Diff: -2.08%, LR: 0.050000
2025-10-01 11:57:47,644 - CIFAR-10_Training - INFO - Starting Epoch 21/200
2025-10-01 11:58:16,032 - CIFAR-10_Training - INFO - Epoch 21: Train Loss: 0.8696, Train Acc: 69.64%, Test Loss: 0.8212, Test Acc: 71.57%, Acc Diff: -1.93%, LR: 0.050000
2025-10-01 11:58:16,032 - CIFAR-10_Training - INFO - Starting Epoch 22/200
2025-10-01 11:58:44,647 - CIFAR-10_Training - INFO - Epoch 22: Train Loss: 0.8635, Train Acc: 69.77%, Test Loss: 0.8131, Test Acc: 71.82%, Acc Diff: -2.05%, LR: 0.050000
2025-10-01 11:58:44,647 - CIFAR-10_Training - INFO - Starting Epoch 23/200
2025-10-01 11:59:13,192 - CIFAR-10_Training - INFO - Epoch 23: Train Loss: 0.8558, Train Acc: 69.91%, Test Loss: 0.8080, Test Acc: 72.30%, Acc Diff: -2.39%, LR: 0.050000
2025-10-01 11:59:13,192 - CIFAR-10_Training - INFO - Starting Epoch 24/200
2025-10-01 11:59:41,985 - CIFAR-10_Training - INFO - Epoch 24: Train Loss: 0.8530, Train Acc: 70.17%, Test Loss: 0.8151, Test Acc: 71.80%, Acc Diff: -1.63%, LR: 0.050000
2025-10-01 11:59:41,985 - CIFAR-10_Training - INFO - Starting Epoch 25/200
2025-10-01 12:00:10,602 - CIFAR-10_Training - INFO - Epoch 25: Train Loss: 0.8442, Train Acc: 70.24%, Test Loss: 0.7889, Test Acc: 72.25%, Acc Diff: -2.01%, LR: 0.050000
2025-10-01 12:00:10,602 - CIFAR-10_Training - INFO - Starting Epoch 26/200
2025-10-01 12:00:39,200 - CIFAR-10_Training - INFO - Epoch 26: Train Loss: 0.8337, Train Acc: 70.78%, Test Loss: 0.7876, Test Acc: 72.65%, Acc Diff: -1.87%, LR: 0.050000
2025-10-01 12:00:39,200 - CIFAR-10_Training - INFO - Starting Epoch 27/200
2025-10-01 12:01:07,543 - CIFAR-10_Training - INFO - Epoch 27: Train Loss: 0.8181, Train Acc: 71.40%, Test Loss: 0.7847, Test Acc: 72.84%, Acc Diff: -1.44%, LR: 0.050000
2025-10-01 12:01:07,543 - CIFAR-10_Training - INFO - Starting Epoch 28/200
2025-10-01 12:01:36,252 - CIFAR-10_Training - INFO - Epoch 28: Train Loss: 0.8236, Train Acc: 71.21%, Test Loss: 0.8021, Test Acc: 72.55%, Acc Diff: -1.34%, LR: 0.050000
2025-10-01 12:01:36,252 - CIFAR-10_Training - INFO - Starting Epoch 29/200
2025-10-01 12:02:04,829 - CIFAR-10_Training - INFO - Epoch 29: Train Loss: 0.8175, Train Acc: 71.23%, Test Loss: 0.8000, Test Acc: 72.49%, Acc Diff: -1.26%, LR: 0.050000
2025-10-01 12:02:04,829 - CIFAR-10_Training - INFO - Starting Epoch 30/200
2025-10-01 12:02:33,100 - CIFAR-10_Training - INFO - Epoch 30: Train Loss: 0.8147, Train Acc: 71.44%, Test Loss: 0.7977, Test Acc: 72.53%, Acc Diff: -1.09%, LR: 0.050000
2025-10-01 12:02:33,100 - CIFAR-10_Training - INFO - Starting Epoch 31/200
2025-10-01 12:03:01,501 - CIFAR-10_Training - INFO - Epoch 31: Train Loss: 0.8033, Train Acc: 71.91%, Test Loss: 0.7950, Test Acc: 72.58%, Acc Diff: -0.67%, LR: 0.050000
2025-10-01 12:03:01,501 - CIFAR-10_Training - INFO - Starting Epoch 32/200
2025-10-01 12:03:30,196 - CIFAR-10_Training - INFO - Epoch 32: Train Loss: 0.8003, Train Acc: 71.78%, Test Loss: 0.7625, Test Acc: 73.80%, Acc Diff: -2.02%, LR: 0.050000
2025-10-01 12:03:30,196 - CIFAR-10_Training - INFO - Starting Epoch 33/200
2025-10-01 12:03:58,739 - CIFAR-10_Training - INFO - Epoch 33: Train Loss: 0.7930, Train Acc: 72.14%, Test Loss: 0.7976, Test Acc: 72.73%, Acc Diff: -0.59%, LR: 0.050000
2025-10-01 12:03:58,739 - CIFAR-10_Training - INFO - Starting Epoch 34/200
2025-10-01 12:04:26,880 - CIFAR-10_Training - INFO - Epoch 34: Train Loss: 0.7900, Train Acc: 72.22%, Test Loss: 0.7663, Test Acc: 73.62%, Acc Diff: -1.40%, LR: 0.050000
2025-10-01 12:04:26,880 - CIFAR-10_Training - INFO - Starting Epoch 35/200
2025-10-01 12:04:55,542 - CIFAR-10_Training - INFO - Epoch 35: Train Loss: 0.7850, Train Acc: 72.72%, Test Loss: 0.7668, Test Acc: 73.50%, Acc Diff: -0.78%, LR: 0.050000
2025-10-01 12:04:55,542 - CIFAR-10_Training - INFO - Starting Epoch 36/200
2025-10-01 12:05:24,134 - CIFAR-10_Training - INFO - Epoch 36: Train Loss: 0.7744, Train Acc: 72.82%, Test Loss: 0.7857, Test Acc: 72.84%, Acc Diff: -0.02%, LR: 0.050000
2025-10-01 12:05:24,134 - CIFAR-10_Training - INFO - Starting Epoch 37/200
2025-10-01 12:05:52,463 - CIFAR-10_Training - INFO - Epoch 37: Train Loss: 0.7737, Train Acc: 72.64%, Test Loss: 0.7677, Test Acc: 74.06%, Acc Diff: -1.42%, LR: 0.050000
2025-10-01 12:05:52,464 - CIFAR-10_Training - INFO - Starting Epoch 38/200
2025-10-01 12:06:21,888 - CIFAR-10_Training - INFO - Epoch 38: Train Loss: 0.7629, Train Acc: 73.23%, Test Loss: 0.7687, Test Acc: 73.63%, Acc Diff: -0.40%, LR: 0.050000
2025-10-01 12:06:21,888 - CIFAR-10_Training - INFO - Starting Epoch 39/200
