2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs\20250930_215240_cifar10_training.log
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO - Updated Configuration (from main()):
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Epochs: 50
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Optimizer: SGD
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Scheduler: StepLR
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Step Size: 10
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Batch Size: 128
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Num Workers: 4
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Pin Memory: True
2025-09-30 21:52:40,628 - CIFAR-10_Training - INFO -   - Shuffle: True
2025-09-30 21:52:40,633 - CIFAR-10_Training - INFO -   - Dropout Rate: 0.05
2025-09-30 21:52:40,633 - CIFAR-10_Training - INFO -   - Device: CUDA
2025-09-30 21:52:40,633 - CIFAR-10_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\logs
2025-09-30 21:52:40,633 - CIFAR-10_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS7\Model_Evolution\Optimize\models
2025-09-30 21:52:40,633 - CIFAR-10_Training - INFO -   - Save Model: True
2025-09-30 21:52:40,633 - CIFAR-10_Training - INFO -   - Log Level: DEBUG
2025-09-30 21:52:40,633 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - CIFAR-10 TRAINING EXPERIMENT STARTED
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=128, num_workers=4, pin_memory=True, shuffle=True, mean=(0.1307,), std=(0.3081,), cifar10_mean=(0.4914, 0.4822, 0.4465), cifar10_std=(0.247, 0.2435, 0.2616), rotation_range=(-7.0, 7.0), fill_value=1)
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - Model Config: ModelConfig(input_channels=1, input_size=(28, 28), num_classes=10, dropout_rate=0.05)
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - Training Config: TrainingConfig(epochs=50, learning_rate=0.05, momentum=0.9, weight_decay=0.0, scheduler_step_size=10, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='StepLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001)
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - Setting up data...
2025-09-30 21:52:40,634 - CIFAR-10_Training - INFO - Loading CIFAR-10 dataset...
2025-09-30 21:52:42,579 - CIFAR-10_Training - INFO - CIFAR-10 dataset loaded successfully!
2025-09-30 21:52:42,579 - CIFAR-10_Training - INFO - Train samples: 50000
2025-09-30 21:52:42,579 - CIFAR-10_Training - INFO - Test samples: 10000
2025-09-30 21:52:42,579 - CIFAR-10_Training - INFO - Computing CIFAR-10 data statistics...
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO - CIFAR-10 Data Statistics:
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   - Size: 153,600,000
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   - Min: 0.0000
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   - Max: 1.0000
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   - Mean: 0.4734
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   - Std: 0.2516
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   - Variance: 0.0633
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO - Channel-wise Statistics:
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   Red Channel:
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -     - Mean: 0.4914
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -     - Std: 0.2470
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -   Green Channel:
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -     - Mean: 0.4822
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -     - Std: 0.2435
2025-09-30 21:52:44,828 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 21:52:44,834 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 21:52:44,834 - CIFAR-10_Training - INFO -   Blue Channel:
2025-09-30 21:52:44,834 - CIFAR-10_Training - INFO -     - Mean: 0.4465
2025-09-30 21:52:44,834 - CIFAR-10_Training - INFO -     - Std: 0.2616
2025-09-30 21:52:44,834 - CIFAR-10_Training - INFO -     - Min: 0.0000
2025-09-30 21:52:44,835 - CIFAR-10_Training - INFO -     - Max: 1.0000
2025-09-30 21:53:04,403 - CIFAR-10_Training - INFO - CIFAR-10 Batch Information:
2025-09-30 21:53:04,404 - CIFAR-10_Training - INFO -   - Batch size: 128
2025-09-30 21:53:04,406 - CIFAR-10_Training - INFO -   - Image shape: torch.Size([3, 32, 32])
2025-09-30 21:53:04,406 - CIFAR-10_Training - INFO -   - Label shape: torch.Size([128])
2025-09-30 21:53:04,408 - CIFAR-10_Training - INFO -   - Data type: torch.float32
2025-09-30 21:53:04,410 - CIFAR-10_Training - INFO -   - Number of classes: 10
2025-09-30 21:53:05,497 - CIFAR-10_Training - INFO - Getting input size from CIFAR-10 data loader...
2025-09-30 21:53:21,223 - CIFAR-10_Training - INFO - CIFAR-10 input size from data loader: (3, 32, 32)
2025-09-30 21:53:22,201 - CIFAR-10_Training - INFO - Setting up model...
2025-09-30 21:53:23,019 - CIFAR-10_Training - INFO - Generating model summary...
2025-09-30 21:53:23,824 - CIFAR-10_Training - INFO - Model Architecture Summary:
2025-09-30 21:53:23,824 - CIFAR-10_Training - INFO -   - Total Parameters: 173,764
2025-09-30 21:53:23,824 - CIFAR-10_Training - INFO -   - Batch Normalization: Yes
2025-09-30 21:53:23,824 - CIFAR-10_Training - INFO -   - Dropout: No
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO -   - GAP Layers: Yes
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO -   - FC Layers: Yes
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO - DETAILED MODEL ARCHITECTURE SUMMARY
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO -         Layer (type)               Output Shape         Param #
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO - ================================================================
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO -             Conv2d-1           [-1, 16, 32, 32]             432
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO -        BatchNorm2d-2           [-1, 16, 32, 32]              32
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO -               ReLU-3           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,827 - CIFAR-10_Training - INFO -          Dropout2d-4           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,832 - CIFAR-10_Training - INFO -             Conv2d-5           [-1, 16, 32, 32]           2,304
2025-09-30 21:53:23,832 - CIFAR-10_Training - INFO -        BatchNorm2d-6           [-1, 16, 32, 32]              32
2025-09-30 21:53:23,832 - CIFAR-10_Training - INFO -               ReLU-7           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,832 - CIFAR-10_Training - INFO -          Dropout2d-8           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,832 - CIFAR-10_Training - INFO -             Conv2d-9           [-1, 16, 32, 32]           2,304
2025-09-30 21:53:23,833 - CIFAR-10_Training - INFO -       BatchNorm2d-10           [-1, 16, 32, 32]              32
2025-09-30 21:53:23,833 - CIFAR-10_Training - INFO -              ReLU-11           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,833 - CIFAR-10_Training - INFO -         Dropout2d-12           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,834 - CIFAR-10_Training - INFO -            Conv2d-13           [-1, 16, 32, 32]           2,304
2025-09-30 21:53:23,834 - CIFAR-10_Training - INFO -       BatchNorm2d-14           [-1, 16, 32, 32]              32
2025-09-30 21:53:23,834 - CIFAR-10_Training - INFO -              ReLU-15           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,834 - CIFAR-10_Training - INFO -         Dropout2d-16           [-1, 16, 32, 32]               0
2025-09-30 21:53:23,834 - CIFAR-10_Training - INFO -            Conv2d-17           [-1, 16, 16, 16]           2,320
2025-09-30 21:53:23,836 - CIFAR-10_Training - INFO -       BatchNorm2d-18           [-1, 16, 16, 16]              32
2025-09-30 21:53:23,836 - CIFAR-10_Training - INFO -            Conv2d-19           [-1, 32, 16, 16]           4,608
2025-09-30 21:53:23,836 - CIFAR-10_Training - INFO -       BatchNorm2d-20           [-1, 32, 16, 16]              64
2025-09-30 21:53:23,836 - CIFAR-10_Training - INFO -              ReLU-21           [-1, 32, 16, 16]               0
2025-09-30 21:53:23,836 - CIFAR-10_Training - INFO -         Dropout2d-22           [-1, 32, 16, 16]               0
2025-09-30 21:53:23,838 - CIFAR-10_Training - INFO -            Conv2d-23           [-1, 32, 16, 16]           9,216
2025-09-30 21:53:23,838 - CIFAR-10_Training - INFO -       BatchNorm2d-24           [-1, 32, 16, 16]              64
2025-09-30 21:53:23,838 - CIFAR-10_Training - INFO -              ReLU-25           [-1, 32, 16, 16]               0
2025-09-30 21:53:23,838 - CIFAR-10_Training - INFO -         Dropout2d-26           [-1, 32, 16, 16]               0
2025-09-30 21:53:23,838 - CIFAR-10_Training - INFO -            Conv2d-27           [-1, 32, 16, 16]           9,216
2025-09-30 21:53:23,838 - CIFAR-10_Training - INFO -       BatchNorm2d-28           [-1, 32, 16, 16]              64
2025-09-30 21:53:23,840 - CIFAR-10_Training - INFO -              ReLU-29           [-1, 32, 16, 16]               0
2025-09-30 21:53:23,840 - CIFAR-10_Training - INFO -         Dropout2d-30           [-1, 32, 16, 16]               0
2025-09-30 21:53:23,840 - CIFAR-10_Training - INFO -            Conv2d-31             [-1, 32, 8, 8]           9,248
2025-09-30 21:53:23,842 - CIFAR-10_Training - INFO -       BatchNorm2d-32             [-1, 32, 8, 8]              64
2025-09-30 21:53:23,843 - CIFAR-10_Training - INFO -            Conv2d-33             [-1, 32, 8, 8]           9,216
2025-09-30 21:53:23,843 - CIFAR-10_Training - INFO -       BatchNorm2d-34             [-1, 32, 8, 8]              64
2025-09-30 21:53:23,843 - CIFAR-10_Training - INFO -              ReLU-35             [-1, 32, 8, 8]               0
2025-09-30 21:53:23,846 - CIFAR-10_Training - INFO -         Dropout2d-36             [-1, 32, 8, 8]               0
2025-09-30 21:53:23,846 - CIFAR-10_Training - INFO -            Conv2d-37             [-1, 32, 8, 8]           9,216
2025-09-30 21:53:23,850 - CIFAR-10_Training - INFO -       BatchNorm2d-38             [-1, 32, 8, 8]              64
2025-09-30 21:53:23,852 - CIFAR-10_Training - INFO -              ReLU-39             [-1, 32, 8, 8]               0
2025-09-30 21:53:23,854 - CIFAR-10_Training - INFO -         Dropout2d-40             [-1, 32, 8, 8]               0
2025-09-30 21:53:23,856 - CIFAR-10_Training - INFO -            Conv2d-41             [-1, 32, 8, 8]           9,216
2025-09-30 21:53:23,856 - CIFAR-10_Training - INFO -       BatchNorm2d-42             [-1, 32, 8, 8]              64
2025-09-30 21:53:23,856 - CIFAR-10_Training - INFO -              ReLU-43             [-1, 32, 8, 8]               0
2025-09-30 21:53:23,858 - CIFAR-10_Training - INFO -         Dropout2d-44             [-1, 32, 8, 8]               0
2025-09-30 21:53:23,860 - CIFAR-10_Training - INFO -            Conv2d-45             [-1, 32, 4, 4]           9,248
2025-09-30 21:53:23,862 - CIFAR-10_Training - INFO -       BatchNorm2d-46             [-1, 32, 4, 4]              64
2025-09-30 21:53:23,864 - CIFAR-10_Training - INFO -            Conv2d-47             [-1, 64, 4, 4]          18,432
2025-09-30 21:53:23,864 - CIFAR-10_Training - INFO -       BatchNorm2d-48             [-1, 64, 4, 4]             128
2025-09-30 21:53:23,864 - CIFAR-10_Training - INFO -              ReLU-49             [-1, 64, 4, 4]               0
2025-09-30 21:53:23,866 - CIFAR-10_Training - INFO -         Dropout2d-50             [-1, 64, 4, 4]               0
2025-09-30 21:53:23,866 - CIFAR-10_Training - INFO -            Conv2d-51             [-1, 64, 4, 4]          36,864
2025-09-30 21:53:23,866 - CIFAR-10_Training - INFO -       BatchNorm2d-52             [-1, 64, 4, 4]             128
2025-09-30 21:53:23,866 - CIFAR-10_Training - INFO -              ReLU-53             [-1, 64, 4, 4]               0
2025-09-30 21:53:23,868 - CIFAR-10_Training - INFO -         Dropout2d-54             [-1, 64, 4, 4]               0
2025-09-30 21:53:23,873 - CIFAR-10_Training - INFO -            Conv2d-55             [-1, 64, 4, 4]          36,864
2025-09-30 21:53:23,874 - CIFAR-10_Training - INFO -       BatchNorm2d-56             [-1, 64, 4, 4]             128
2025-09-30 21:53:23,874 - CIFAR-10_Training - INFO -              ReLU-57             [-1, 64, 4, 4]               0
2025-09-30 21:53:23,874 - CIFAR-10_Training - INFO -         Dropout2d-58             [-1, 64, 4, 4]               0
2025-09-30 21:53:23,874 - CIFAR-10_Training - INFO -            Conv2d-59             [-1, 10, 4, 4]             640
2025-09-30 21:53:23,874 - CIFAR-10_Training - INFO -         AvgPool2d-60             [-1, 10, 1, 1]               0
2025-09-30 21:53:23,874 - CIFAR-10_Training - INFO -            Linear-61                   [-1, 50]             550
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO -            Linear-62                   [-1, 10]             510
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - ================================================================
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Total params: 173,764
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Trainable params: 173,764
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Non-trainable params: 0
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Input size (MB): 0.01
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Forward/backward pass size (MB): 3.13
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Params size (MB): 0.66
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Estimated Total Size (MB): 3.81
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - ----------------------------------------------------------------
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - ==================================================
2025-09-30 21:53:23,877 - CIFAR-10_Training - INFO - Setting up trainer...
2025-09-30 21:53:23,885 - CIFAR-10_Training - INFO - Using device: cuda
2025-09-30 21:53:23,885 - CIFAR-10_Training - INFO - Early stopping: Stop if train_acc - test_acc > 15.0% for 10 epochs
2025-09-30 21:53:23,885 - CIFAR-10_Training - INFO - Starting training process...
2025-09-30 21:53:23,885 - CIFAR-10_Training - INFO - Starting training process...
2025-09-30 21:53:23,887 - CIFAR-10_Training - INFO - Using optimizer: SGD
2025-09-30 21:53:23,887 - CIFAR-10_Training - INFO - Using scheduler: StepLR
2025-09-30 21:53:23,898 - CIFAR-10_Training - INFO - Optimizer Configuration:
2025-09-30 21:53:23,901 - CIFAR-10_Training - INFO -   - Learning Rate: 0.05
2025-09-30 21:53:23,903 - CIFAR-10_Training - INFO -   - Momentum: 0.9
2025-09-30 21:53:23,905 - CIFAR-10_Training - INFO -   - Weight Decay: 0.0
2025-09-30 21:53:23,907 - CIFAR-10_Training - INFO - Scheduler Configuration:
2025-09-30 21:53:23,908 - CIFAR-10_Training - INFO -   - Step Size: 10
2025-09-30 21:53:23,908 - CIFAR-10_Training - INFO -   - Gamma: 0.1
2025-09-30 21:53:23,908 - CIFAR-10_Training - INFO - Starting Epoch 1/50
2025-09-30 21:54:16,382 - CIFAR-10_Training - INFO - Epoch  1: Train Loss: 1.9090, Train Acc: 27.16%, Test Loss: 1.6186, Test Acc: 37.89%, Acc Diff: -10.73%, LR: 0.050000
2025-09-30 21:54:16,382 - CIFAR-10_Training - INFO - Starting Epoch 2/50
2025-09-30 21:55:11,431 - CIFAR-10_Training - INFO - Epoch  2: Train Loss: 1.6474, Train Acc: 37.99%, Test Loss: 1.5158, Test Acc: 40.15%, Acc Diff: -2.16%, LR: 0.050000
2025-09-30 21:55:11,431 - CIFAR-10_Training - INFO - Starting Epoch 3/50
2025-09-30 21:56:11,861 - CIFAR-10_Training - INFO - Epoch  3: Train Loss: 1.5336, Train Acc: 43.71%, Test Loss: 1.4002, Test Acc: 48.74%, Acc Diff: -5.03%, LR: 0.050000
2025-09-30 21:56:11,861 - CIFAR-10_Training - INFO - Starting Epoch 4/50
2025-09-30 21:57:09,862 - CIFAR-10_Training - INFO - Epoch  4: Train Loss: 1.4445, Train Acc: 47.55%, Test Loss: 1.3085, Test Acc: 52.18%, Acc Diff: -4.63%, LR: 0.050000
2025-09-30 21:57:09,862 - CIFAR-10_Training - INFO - Starting Epoch 5/50
2025-09-30 21:58:09,082 - CIFAR-10_Training - INFO - Epoch  5: Train Loss: 1.3719, Train Acc: 50.70%, Test Loss: 1.2188, Test Acc: 55.24%, Acc Diff: -4.54%, LR: 0.050000
2025-09-30 21:58:09,082 - CIFAR-10_Training - INFO - Starting Epoch 6/50
2025-09-30 21:59:07,254 - CIFAR-10_Training - INFO - Epoch  6: Train Loss: 1.3121, Train Acc: 52.83%, Test Loss: 1.1646, Test Acc: 57.89%, Acc Diff: -5.06%, LR: 0.050000
2025-09-30 21:59:07,254 - CIFAR-10_Training - INFO - Starting Epoch 7/50
2025-09-30 22:00:04,613 - CIFAR-10_Training - INFO - Epoch  7: Train Loss: 1.2565, Train Acc: 55.15%, Test Loss: 1.1273, Test Acc: 59.11%, Acc Diff: -3.96%, LR: 0.050000
2025-09-30 22:00:04,613 - CIFAR-10_Training - INFO - Starting Epoch 8/50
2025-09-30 22:01:03,749 - CIFAR-10_Training - INFO - Epoch  8: Train Loss: 1.2178, Train Acc: 56.64%, Test Loss: 1.1043, Test Acc: 60.18%, Acc Diff: -3.54%, LR: 0.050000
2025-09-30 22:01:03,751 - CIFAR-10_Training - INFO - Starting Epoch 9/50
2025-09-30 22:02:01,634 - CIFAR-10_Training - INFO - Epoch  9: Train Loss: 1.1787, Train Acc: 58.30%, Test Loss: 1.0502, Test Acc: 62.43%, Acc Diff: -4.13%, LR: 0.050000
2025-09-30 22:02:01,634 - CIFAR-10_Training - INFO - Starting Epoch 10/50
2025-09-30 22:02:56,896 - CIFAR-10_Training - INFO - Epoch 10: Train Loss: 1.1523, Train Acc: 59.15%, Test Loss: 1.0124, Test Acc: 64.24%, Acc Diff: -5.09%, LR: 0.005000
2025-09-30 22:02:56,896 - CIFAR-10_Training - INFO - Starting Epoch 11/50
2025-09-30 22:03:51,457 - CIFAR-10_Training - INFO - Epoch 11: Train Loss: 1.0696, Train Acc: 62.16%, Test Loss: 0.9350, Test Acc: 66.85%, Acc Diff: -4.69%, LR: 0.005000
2025-09-30 22:03:51,458 - CIFAR-10_Training - INFO - Starting Epoch 12/50
2025-09-30 22:04:46,152 - CIFAR-10_Training - INFO - Epoch 12: Train Loss: 1.0493, Train Acc: 62.74%, Test Loss: 0.9294, Test Acc: 66.80%, Acc Diff: -4.06%, LR: 0.005000
2025-09-30 22:04:46,152 - CIFAR-10_Training - INFO - Starting Epoch 13/50
2025-09-30 22:05:42,841 - CIFAR-10_Training - INFO - Epoch 13: Train Loss: 1.0445, Train Acc: 62.86%, Test Loss: 0.9266, Test Acc: 67.06%, Acc Diff: -4.20%, LR: 0.005000
2025-09-30 22:05:42,841 - CIFAR-10_Training - INFO - Starting Epoch 14/50
2025-09-30 22:06:40,936 - CIFAR-10_Training - INFO - Epoch 14: Train Loss: 1.0339, Train Acc: 63.14%, Test Loss: 0.9240, Test Acc: 67.09%, Acc Diff: -3.95%, LR: 0.005000
2025-09-30 22:06:40,936 - CIFAR-10_Training - INFO - Starting Epoch 15/50
2025-09-30 22:07:34,849 - CIFAR-10_Training - INFO - Epoch 15: Train Loss: 1.0227, Train Acc: 63.66%, Test Loss: 0.9138, Test Acc: 67.22%, Acc Diff: -3.56%, LR: 0.005000
2025-09-30 22:07:34,849 - CIFAR-10_Training - INFO - Starting Epoch 16/50
2025-09-30 22:08:30,363 - CIFAR-10_Training - INFO - Epoch 16: Train Loss: 1.0241, Train Acc: 63.72%, Test Loss: 0.9154, Test Acc: 67.52%, Acc Diff: -3.80%, LR: 0.005000
2025-09-30 22:08:30,366 - CIFAR-10_Training - INFO - Starting Epoch 17/50
2025-09-30 22:09:26,790 - CIFAR-10_Training - INFO - Epoch 17: Train Loss: 1.0172, Train Acc: 64.04%, Test Loss: 0.9090, Test Acc: 67.53%, Acc Diff: -3.49%, LR: 0.005000
2025-09-30 22:09:26,790 - CIFAR-10_Training - INFO - Starting Epoch 18/50
2025-09-30 22:10:21,478 - CIFAR-10_Training - INFO - Epoch 18: Train Loss: 1.0226, Train Acc: 63.69%, Test Loss: 0.9110, Test Acc: 67.55%, Acc Diff: -3.86%, LR: 0.005000
2025-09-30 22:10:21,478 - CIFAR-10_Training - INFO - Starting Epoch 19/50
2025-09-30 22:11:17,929 - CIFAR-10_Training - INFO - Epoch 19: Train Loss: 1.0083, Train Acc: 64.19%, Test Loss: 0.9031, Test Acc: 67.60%, Acc Diff: -3.41%, LR: 0.005000
2025-09-30 22:11:17,929 - CIFAR-10_Training - INFO - Starting Epoch 20/50
2025-09-30 22:12:10,564 - CIFAR-10_Training - INFO - Epoch 20: Train Loss: 1.0133, Train Acc: 64.25%, Test Loss: 0.8985, Test Acc: 68.09%, Acc Diff: -3.84%, LR: 0.000500
2025-09-30 22:12:10,565 - CIFAR-10_Training - INFO - Starting Epoch 21/50
2025-09-30 22:13:06,308 - CIFAR-10_Training - INFO - Epoch 21: Train Loss: 1.0048, Train Acc: 64.35%, Test Loss: 0.8959, Test Acc: 68.09%, Acc Diff: -3.74%, LR: 0.000500
2025-09-30 22:13:06,308 - CIFAR-10_Training - INFO - Starting Epoch 22/50
2025-09-30 22:14:02,167 - CIFAR-10_Training - INFO - Epoch 22: Train Loss: 0.9992, Train Acc: 64.68%, Test Loss: 0.8943, Test Acc: 68.19%, Acc Diff: -3.51%, LR: 0.000500
2025-09-30 22:14:02,167 - CIFAR-10_Training - INFO - Starting Epoch 23/50
