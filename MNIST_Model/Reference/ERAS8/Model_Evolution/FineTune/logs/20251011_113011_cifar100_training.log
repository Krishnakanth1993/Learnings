2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\logs\20251011_113011_cifar100_training.log
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - Updated Configuration (from main()):
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Epochs: 100
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Learning Rate: 0.00251
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Optimizer: SGD
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Weight Decay: 0.0001
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Momentum: 0.9
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Scheduler: OneCycleLR
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Max LR: 0.01
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Pct Start: 0.3
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Div Factor: 10.0
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Final Div Factor: 1000.0
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Anneal Strategy: cos
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Batch Size: 128
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Num Workers: 4
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Pin Memory: True
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Shuffle: True
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Dropout Rate: 0.0
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Device: CUDA
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\logs
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\models
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Save Model: True
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO -   - Log Level: INFO
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - CIFAR-100 TRAINING EXPERIMENT STARTED
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=128, num_workers=4, pin_memory=True, shuffle=True, cifar100_mean=(0.507076, 0.48655, 0.440919), cifar100_std=(0.267334, 0.256438, 0.27615), rotation_range=(-7.0, 7.0), fill_value=1)
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - Model Config: ModelConfig(input_channels=3, input_size=(32, 32), num_classes=100, dropout_rate=0.0)
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - Training Config: TrainingConfig(epochs=100, learning_rate=0.00251, momentum=0.9, weight_decay=0.0001, scheduler_step_size=10, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='OneCycleLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001, onecycle_max_lr=0.01, onecycle_pct_start=0.3, onecycle_div_factor=10.0, onecycle_final_div_factor=1000.0, onecycle_anneal_strategy='cos')
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - Setting up data...
2025-10-11 11:30:11,305 - CIFAR-100_Training - INFO - Using Albumentations for data augmentation
2025-10-11 11:30:11,314 - CIFAR-100_Training - INFO - Loading CIFAR-100 dataset...
2025-10-11 11:30:12,597 - CIFAR-100_Training - INFO - CIFAR-100 dataset loaded successfully!
2025-10-11 11:30:12,597 - CIFAR-100_Training - INFO - Train samples: 50000
2025-10-11 11:30:12,597 - CIFAR-100_Training - INFO - Test samples: 10000
2025-10-11 11:30:12,597 - CIFAR-100_Training - INFO - Augmentation library: Albumentations
2025-10-11 11:30:12,597 - CIFAR-100_Training - INFO - Computing CIFAR-100 data statistics...
2025-10-11 11:30:14,361 - CIFAR-100_Training - INFO - CIFAR-100 Data Statistics:
2025-10-11 11:30:14,361 - CIFAR-100_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-10-11 11:30:14,361 - CIFAR-100_Training - INFO -   - Size: 153,600,000
2025-10-11 11:30:14,361 - CIFAR-100_Training - INFO -   - Min: 0.0000
2025-10-11 11:30:14,361 - CIFAR-100_Training - INFO -   - Max: 1.0000
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO -   - Mean: 0.4782
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO -   - Std: 0.2682
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO -   - Variance: 0.0719
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO - Channel-wise Statistics:
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO -   Red Channel:
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO -     - Mean: 0.5071
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO -     - Std: 0.2673
2025-10-11 11:30:14,366 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 11:30:14,371 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 11:30:14,372 - CIFAR-100_Training - INFO -   Green Channel:
2025-10-11 11:30:14,373 - CIFAR-100_Training - INFO -     - Mean: 0.4865
2025-10-11 11:30:14,374 - CIFAR-100_Training - INFO -     - Std: 0.2564
2025-10-11 11:30:14,374 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 11:30:14,375 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 11:30:14,376 - CIFAR-100_Training - INFO -   Blue Channel:
2025-10-11 11:30:14,377 - CIFAR-100_Training - INFO -     - Mean: 0.4409
2025-10-11 11:30:14,378 - CIFAR-100_Training - INFO -     - Std: 0.2762
2025-10-11 11:30:14,378 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 11:30:14,379 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 11:30:28,596 - CIFAR-100_Training - INFO - CIFAR-100 Batch Information:
2025-10-11 11:30:28,596 - CIFAR-100_Training - INFO -   - Batch size: 128
2025-10-11 11:30:28,596 - CIFAR-100_Training - INFO -   - Image shape: torch.Size([3, 32, 32])
2025-10-11 11:30:28,596 - CIFAR-100_Training - INFO -   - Label shape: torch.Size([128])
2025-10-11 11:30:28,596 - CIFAR-100_Training - INFO -   - Data type: torch.float32
2025-10-11 11:30:28,596 - CIFAR-100_Training - INFO -   - Number of classes: 100
2025-10-11 11:30:29,782 - CIFAR-100_Training - INFO - Getting input size from CIFAR-100 data loader...
2025-10-11 11:30:42,101 - CIFAR-100_Training - INFO - CIFAR-100 input size from data loader: (3, 32, 32)
2025-10-11 11:30:43,252 - CIFAR-100_Training - INFO - Setting up model...
2025-10-11 11:30:43,655 - CIFAR-100_Training - INFO - Generating ResNet-34 summary...
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO - ResNet-34 Architecture Summary:
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -   - Total Parameters: 21,328,292
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -   - Batch Normalization: Yes
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -   - Dropout: Yes
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -   - FC Layers: Yes
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -   - GAP Layers: Yes
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO - DETAILED MODEL ARCHITECTURE SUMMARY
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO - ----------------------------------------------------------------
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -         Layer (type)               Output Shape         Param #
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO - ================================================================
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -             Conv2d-1           [-1, 64, 32, 32]           1,728
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BatchNorm2d-2           [-1, 64, 32, 32]             128
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -               ReLU-3           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -             Conv2d-4           [-1, 64, 32, 32]          36,864
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BatchNorm2d-5           [-1, 64, 32, 32]             128
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -               ReLU-6           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -             Conv2d-7           [-1, 64, 32, 32]          36,864
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BatchNorm2d-8           [-1, 64, 32, 32]             128
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -               ReLU-9           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BasicBlock-10           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-11           [-1, 64, 32, 32]          36,864
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-12           [-1, 64, 32, 32]             128
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-13           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-14           [-1, 64, 32, 32]          36,864
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-15           [-1, 64, 32, 32]             128
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-16           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BasicBlock-17           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-18           [-1, 64, 32, 32]          36,864
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-19           [-1, 64, 32, 32]             128
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-20           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-21           [-1, 64, 32, 32]          36,864
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-22           [-1, 64, 32, 32]             128
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-23           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BasicBlock-24           [-1, 64, 32, 32]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-25          [-1, 128, 16, 16]          73,728
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-26          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-27          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-28          [-1, 128, 16, 16]         147,456
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-29          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-30          [-1, 128, 16, 16]           8,192
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-31          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-32          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BasicBlock-33          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-34          [-1, 128, 16, 16]         147,456
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-35          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-36          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-37          [-1, 128, 16, 16]         147,456
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-38          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-39          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BasicBlock-40          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-41          [-1, 128, 16, 16]         147,456
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-42          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-43          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-44          [-1, 128, 16, 16]         147,456
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-45          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-46          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BasicBlock-47          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-48          [-1, 128, 16, 16]         147,456
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-49          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-50          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-51          [-1, 128, 16, 16]         147,456
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -       BatchNorm2d-52          [-1, 128, 16, 16]             256
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -              ReLU-53          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -        BasicBlock-54          [-1, 128, 16, 16]               0
2025-10-11 11:30:44,269 - CIFAR-100_Training - INFO -            Conv2d-55            [-1, 256, 8, 8]         294,912
2025-10-11 11:30:44,277 - CIFAR-100_Training - INFO -       BatchNorm2d-56            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,277 - CIFAR-100_Training - INFO -              ReLU-57            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,277 - CIFAR-100_Training - INFO -            Conv2d-58            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,277 - CIFAR-100_Training - INFO -       BatchNorm2d-59            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,278 - CIFAR-100_Training - INFO -            Conv2d-60            [-1, 256, 8, 8]          32,768
2025-10-11 11:30:44,278 - CIFAR-100_Training - INFO -       BatchNorm2d-61            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,278 - CIFAR-100_Training - INFO -              ReLU-62            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,278 - CIFAR-100_Training - INFO -        BasicBlock-63            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,278 - CIFAR-100_Training - INFO -            Conv2d-64            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,278 - CIFAR-100_Training - INFO -       BatchNorm2d-65            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -              ReLU-66            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -            Conv2d-67            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -       BatchNorm2d-68            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -              ReLU-69            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -        BasicBlock-70            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -            Conv2d-71            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -       BatchNorm2d-72            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -              ReLU-73            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -            Conv2d-74            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,279 - CIFAR-100_Training - INFO -       BatchNorm2d-75            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -              ReLU-76            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -        BasicBlock-77            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -            Conv2d-78            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BatchNorm2d-79            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -              ReLU-80            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -            Conv2d-81            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BatchNorm2d-82            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -              ReLU-83            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -        BasicBlock-84            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -            Conv2d-85            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BatchNorm2d-86            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -              ReLU-87            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -            Conv2d-88            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BatchNorm2d-89            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -              ReLU-90            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -        BasicBlock-91            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -            Conv2d-92            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BatchNorm2d-93            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -              ReLU-94            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -            Conv2d-95            [-1, 256, 8, 8]         589,824
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BatchNorm2d-96            [-1, 256, 8, 8]             512
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -              ReLU-97            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -        BasicBlock-98            [-1, 256, 8, 8]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -            Conv2d-99            [-1, 512, 4, 4]       1,179,648
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -      BatchNorm2d-100            [-1, 512, 4, 4]           1,024
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -             ReLU-101            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -           Conv2d-102            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -      BatchNorm2d-103            [-1, 512, 4, 4]           1,024
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -           Conv2d-104            [-1, 512, 4, 4]         131,072
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -      BatchNorm2d-105            [-1, 512, 4, 4]           1,024
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -             ReLU-106            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BasicBlock-107            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -           Conv2d-108            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -      BatchNorm2d-109            [-1, 512, 4, 4]           1,024
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -             ReLU-110            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -           Conv2d-111            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -      BatchNorm2d-112            [-1, 512, 4, 4]           1,024
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -             ReLU-113            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -       BasicBlock-114            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -           Conv2d-115            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -      BatchNorm2d-116            [-1, 512, 4, 4]           1,024
2025-10-11 11:30:44,280 - CIFAR-100_Training - INFO -             ReLU-117            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,285 - CIFAR-100_Training - INFO -           Conv2d-118            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:30:44,285 - CIFAR-100_Training - INFO -      BatchNorm2d-119            [-1, 512, 4, 4]           1,024
2025-10-11 11:30:44,285 - CIFAR-100_Training - INFO -             ReLU-120            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,285 - CIFAR-100_Training - INFO -       BasicBlock-121            [-1, 512, 4, 4]               0
2025-10-11 11:30:44,285 - CIFAR-100_Training - INFO - AdaptiveAvgPool2d-122            [-1, 512, 1, 1]               0
2025-10-11 11:30:44,285 - CIFAR-100_Training - INFO -          Dropout-123                  [-1, 512]               0
2025-10-11 11:30:44,285 - CIFAR-100_Training - INFO -           Linear-124                  [-1, 100]          51,300
2025-10-11 11:30:44,286 - CIFAR-100_Training - INFO - ================================================================
2025-10-11 11:30:44,286 - CIFAR-100_Training - INFO - Total params: 21,328,292
2025-10-11 11:30:44,286 - CIFAR-100_Training - INFO - Trainable params: 21,328,292
2025-10-11 11:30:44,286 - CIFAR-100_Training - INFO - Non-trainable params: 0
2025-10-11 11:30:44,286 - CIFAR-100_Training - INFO - ----------------------------------------------------------------
2025-10-11 11:30:44,286 - CIFAR-100_Training - INFO - Input size (MB): 0.01
2025-10-11 11:30:44,287 - CIFAR-100_Training - INFO - Forward/backward pass size (MB): 26.45
2025-10-11 11:30:44,287 - CIFAR-100_Training - INFO - Params size (MB): 81.36
2025-10-11 11:30:44,287 - CIFAR-100_Training - INFO - Estimated Total Size (MB): 107.82
2025-10-11 11:30:44,287 - CIFAR-100_Training - INFO - ----------------------------------------------------------------
2025-10-11 11:30:44,287 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:30:44,287 - CIFAR-100_Training - INFO - Setting up trainer...
2025-10-11 11:30:44,291 - CIFAR-100_Training - INFO - Using device: cuda
2025-10-11 11:30:44,292 - CIFAR-100_Training - INFO - Early stopping: Stop if train_acc - test_acc > 15.0% for 10 epochs
2025-10-11 11:30:44,292 - CIFAR-100_Training - INFO - Starting training process...
2025-10-11 11:30:44,292 - CIFAR-100_Training - INFO - Starting training process...
2025-10-11 11:30:44,294 - CIFAR-100_Training - INFO - Using optimizer: SGD
2025-10-11 11:30:44,294 - CIFAR-100_Training - INFO - Using scheduler: OneCycleLR
2025-10-11 11:30:44,294 - CIFAR-100_Training - INFO - Optimizer Configuration:
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Learning Rate: 0.00251
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Momentum: 0.9
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Weight Decay: 0.0001
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO - Scheduler Configuration:
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Max LR: 0.01
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Steps per Epoch: 391
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Pct Start: 0.3
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Div Factor: 10.0
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Final Div Factor: 1000.0
2025-10-11 11:30:44,295 - CIFAR-100_Training - INFO -   - Anneal Strategy: cos
2025-10-11 11:30:44,296 - CIFAR-100_Training - INFO - Starting Epoch 1/100
2025-10-11 11:33:07,835 - CIFAR-100_Training - INFO - Epoch  1: Train Loss: 4.2792, Train Acc: 5.28%, Test Loss: 3.9036, Test Acc: 9.88%, Acc Diff: -4.60%, LR: 0.001025
2025-10-11 11:33:07,835 - CIFAR-100_Training - INFO - Starting Epoch 2/100
2025-10-11 11:35:30,157 - CIFAR-100_Training - INFO - Epoch  2: Train Loss: 3.7123, Train Acc: 13.01%, Test Loss: 3.5129, Test Acc: 16.33%, Acc Diff: -3.32%, LR: 0.001098
2025-10-11 11:35:30,157 - CIFAR-100_Training - INFO - Starting Epoch 3/100
2025-10-11 11:37:52,893 - CIFAR-100_Training - INFO - Epoch  3: Train Loss: 3.3916, Train Acc: 18.38%, Test Loss: 3.2675, Test Acc: 20.54%, Acc Diff: -2.16%, LR: 0.001220
2025-10-11 11:37:52,893 - CIFAR-100_Training - INFO - Starting Epoch 4/100
2025-10-11 11:40:15,389 - CIFAR-100_Training - INFO - Epoch  4: Train Loss: 3.1473, Train Acc: 22.73%, Test Loss: 3.0126, Test Acc: 25.50%, Acc Diff: -2.77%, LR: 0.001389
2025-10-11 11:40:15,389 - CIFAR-100_Training - INFO - Starting Epoch 5/100
2025-10-11 11:42:37,640 - CIFAR-100_Training - INFO - Epoch  5: Train Loss: 2.9388, Train Acc: 26.47%, Test Loss: 2.9133, Test Acc: 27.34%, Acc Diff: -0.87%, LR: 0.001603
2025-10-11 11:42:37,640 - CIFAR-100_Training - INFO - Starting Epoch 6/100
2025-10-11 11:45:00,089 - CIFAR-100_Training - INFO - Epoch  6: Train Loss: 2.7492, Train Acc: 30.42%, Test Loss: 2.7115, Test Acc: 31.25%, Acc Diff: -0.83%, LR: 0.001860
2025-10-11 11:45:00,089 - CIFAR-100_Training - INFO - Starting Epoch 7/100
2025-10-11 11:47:22,358 - CIFAR-100_Training - INFO - Epoch  7: Train Loss: 2.5708, Train Acc: 34.01%, Test Loss: 2.5625, Test Acc: 34.58%, Acc Diff: -0.57%, LR: 0.002156
2025-10-11 11:47:22,358 - CIFAR-100_Training - INFO - Starting Epoch 8/100
2025-10-11 11:49:44,645 - CIFAR-100_Training - INFO - Epoch  8: Train Loss: 2.3972, Train Acc: 37.47%, Test Loss: 2.4163, Test Acc: 37.43%, Acc Diff: 0.04%, LR: 0.002489
2025-10-11 11:49:44,645 - CIFAR-100_Training - INFO - Starting Epoch 9/100
2025-10-11 11:52:06,891 - CIFAR-100_Training - INFO - Epoch  9: Train Loss: 2.2356, Train Acc: 40.79%, Test Loss: 2.3036, Test Acc: 39.06%, Acc Diff: 1.73%, LR: 0.002855
2025-10-11 11:52:06,891 - CIFAR-100_Training - INFO - Starting Epoch 10/100
2025-10-11 11:54:29,193 - CIFAR-100_Training - INFO - Epoch 10: Train Loss: 2.0736, Train Acc: 44.49%, Test Loss: 2.1661, Test Acc: 42.19%, Acc Diff: 2.30%, LR: 0.003250
2025-10-11 11:54:29,193 - CIFAR-100_Training - INFO - Starting Epoch 11/100
2025-10-11 11:56:51,425 - CIFAR-100_Training - INFO - Epoch 11: Train Loss: 1.9426, Train Acc: 47.31%, Test Loss: 2.3455, Test Acc: 40.12%, Acc Diff: 7.19%, LR: 0.003670
2025-10-11 11:56:51,425 - CIFAR-100_Training - INFO - Starting Epoch 12/100
2025-10-11 11:59:13,720 - CIFAR-100_Training - INFO - Epoch 12: Train Loss: 1.8078, Train Acc: 50.37%, Test Loss: 1.9579, Test Acc: 47.73%, Acc Diff: 2.64%, LR: 0.004110
2025-10-11 11:59:13,720 - CIFAR-100_Training - INFO - Starting Epoch 13/100
2025-10-11 12:01:36,408 - CIFAR-100_Training - INFO - Epoch 13: Train Loss: 1.6943, Train Acc: 53.02%, Test Loss: 1.9129, Test Acc: 48.79%, Acc Diff: 4.23%, LR: 0.004565
2025-10-11 12:01:36,408 - CIFAR-100_Training - INFO - Starting Epoch 14/100
2025-10-11 12:03:59,400 - CIFAR-100_Training - INFO - Epoch 14: Train Loss: 1.5790, Train Acc: 55.60%, Test Loss: 1.8749, Test Acc: 50.13%, Acc Diff: 5.47%, LR: 0.005030
2025-10-11 12:03:59,400 - CIFAR-100_Training - INFO - Starting Epoch 15/100
2025-10-11 12:06:21,629 - CIFAR-100_Training - INFO - Epoch 15: Train Loss: 1.4911, Train Acc: 58.06%, Test Loss: 1.8645, Test Acc: 50.81%, Acc Diff: 7.25%, LR: 0.005501
2025-10-11 12:06:21,629 - CIFAR-100_Training - INFO - Starting Epoch 16/100
2025-10-11 12:08:45,134 - CIFAR-100_Training - INFO - Epoch 16: Train Loss: 1.3876, Train Acc: 60.57%, Test Loss: 2.0145, Test Acc: 48.42%, Acc Diff: 12.15%, LR: 0.005971
2025-10-11 12:08:45,134 - CIFAR-100_Training - INFO - Starting Epoch 17/100
2025-10-11 12:11:07,736 - CIFAR-100_Training - INFO - Epoch 17: Train Loss: 1.3056, Train Acc: 62.63%, Test Loss: 1.8583, Test Acc: 51.58%, Acc Diff: 11.05%, LR: 0.006436
2025-10-11 12:11:07,738 - CIFAR-100_Training - INFO - Starting Epoch 18/100
2025-10-11 12:13:30,328 - CIFAR-100_Training - INFO - Epoch 18: Train Loss: 1.2216, Train Acc: 64.73%, Test Loss: 1.8535, Test Acc: 52.45%, Acc Diff: 12.28%, LR: 0.006891
2025-10-11 12:13:30,328 - CIFAR-100_Training - INFO - Starting Epoch 19/100
2025-10-11 12:15:52,663 - CIFAR-100_Training - INFO - Epoch 19: Train Loss: 1.1551, Train Acc: 66.47%, Test Loss: 1.7177, Test Acc: 53.83%, Acc Diff: 12.64%, LR: 0.007331
2025-10-11 12:15:52,663 - CIFAR-100_Training - INFO - Starting Epoch 20/100
2025-10-11 12:18:15,077 - CIFAR-100_Training - INFO - Epoch 20: Train Loss: 1.0663, Train Acc: 68.58%, Test Loss: 1.8749, Test Acc: 51.53%, Acc Diff: 17.05%, LR: 0.007751 (OVERFITTING: 1 epochs)
2025-10-11 12:18:15,077 - CIFAR-100_Training - INFO - Starting Epoch 21/100
2025-10-11 12:20:37,800 - CIFAR-100_Training - INFO - Epoch 21: Train Loss: 1.0001, Train Acc: 70.33%, Test Loss: 1.8302, Test Acc: 54.26%, Acc Diff: 16.07%, LR: 0.008146 (OVERFITTING: 2 epochs)
2025-10-11 12:20:37,800 - CIFAR-100_Training - INFO - Starting Epoch 22/100
2025-10-11 12:23:00,118 - CIFAR-100_Training - INFO - Epoch 22: Train Loss: 0.9400, Train Acc: 72.00%, Test Loss: 1.8343, Test Acc: 54.49%, Acc Diff: 17.51%, LR: 0.008512 (OVERFITTING: 3 epochs)
2025-10-11 12:23:00,118 - CIFAR-100_Training - INFO - Starting Epoch 23/100
2025-10-11 12:25:22,473 - CIFAR-100_Training - INFO - Epoch 23: Train Loss: 0.8756, Train Acc: 73.76%, Test Loss: 1.7002, Test Acc: 56.74%, Acc Diff: 17.02%, LR: 0.008845 (OVERFITTING: 4 epochs)
2025-10-11 12:25:22,473 - CIFAR-100_Training - INFO - Starting Epoch 24/100
2025-10-11 12:27:45,068 - CIFAR-100_Training - INFO - Epoch 24: Train Loss: 0.8197, Train Acc: 75.30%, Test Loss: 1.7755, Test Acc: 57.00%, Acc Diff: 18.30%, LR: 0.009141 (OVERFITTING: 5 epochs)
2025-10-11 12:27:45,068 - CIFAR-100_Training - INFO - Starting Epoch 25/100
2025-10-11 12:30:07,366 - CIFAR-100_Training - INFO - Epoch 25: Train Loss: 0.7587, Train Acc: 77.02%, Test Loss: 1.7953, Test Acc: 55.78%, Acc Diff: 21.24%, LR: 0.009398 (OVERFITTING: 6 epochs)
2025-10-11 12:30:07,366 - CIFAR-100_Training - INFO - Starting Epoch 26/100
2025-10-11 12:32:33,772 - CIFAR-100_Training - INFO - Epoch 26: Train Loss: 0.7059, Train Acc: 78.65%, Test Loss: 1.7737, Test Acc: 57.05%, Acc Diff: 21.60%, LR: 0.009611 (OVERFITTING: 7 epochs)
2025-10-11 12:32:33,772 - CIFAR-100_Training - INFO - Starting Epoch 27/100
2025-10-11 12:35:08,072 - CIFAR-100_Training - INFO - Epoch 27: Train Loss: 0.6587, Train Acc: 79.95%, Test Loss: 1.7749, Test Acc: 57.87%, Acc Diff: 22.08%, LR: 0.009780 (OVERFITTING: 8 epochs)
2025-10-11 12:35:08,072 - CIFAR-100_Training - INFO - Starting Epoch 28/100
2025-10-11 12:37:39,045 - CIFAR-100_Training - INFO - Epoch 28: Train Loss: 0.6157, Train Acc: 81.08%, Test Loss: 1.9069, Test Acc: 56.29%, Acc Diff: 24.79%, LR: 0.009902 (OVERFITTING: 9 epochs)
2025-10-11 12:37:39,045 - CIFAR-100_Training - INFO - Starting Epoch 29/100
2025-10-11 12:40:07,792 - CIFAR-100_Training - INFO - Epoch 29: Train Loss: 0.5742, Train Acc: 82.38%, Test Loss: 1.8417, Test Acc: 57.30%, Acc Diff: 25.08%, LR: 0.009975 (OVERFITTING: 10 epochs)
2025-10-11 12:40:07,792 - CIFAR-100_Training - INFO - Starting Epoch 30/100
2025-10-11 12:42:34,060 - CIFAR-100_Training - INFO - Epoch 30: Train Loss: 0.5281, Train Acc: 83.73%, Test Loss: 1.7229, Test Acc: 58.96%, Acc Diff: 24.77%, LR: 0.010000 (OVERFITTING: 11 epochs)
2025-10-11 12:42:34,060 - CIFAR-100_Training - INFO - Starting Epoch 31/100
2025-10-11 12:44:56,186 - CIFAR-100_Training - INFO - Epoch 31: Train Loss: 0.4934, Train Acc: 84.91%, Test Loss: 1.7277, Test Acc: 60.04%, Acc Diff: 24.87%, LR: 0.009995 (OVERFITTING: 12 epochs)
2025-10-11 12:44:56,186 - CIFAR-100_Training - INFO - Starting Epoch 32/100
2025-10-11 12:47:19,141 - CIFAR-100_Training - INFO - Epoch 32: Train Loss: 0.4611, Train Acc: 85.64%, Test Loss: 1.8549, Test Acc: 57.53%, Acc Diff: 28.11%, LR: 0.009980 (OVERFITTING: 13 epochs)
2025-10-11 12:47:19,141 - CIFAR-100_Training - INFO - Starting Epoch 33/100
2025-10-11 12:49:41,868 - CIFAR-100_Training - INFO - Epoch 33: Train Loss: 0.4274, Train Acc: 86.80%, Test Loss: 1.7581, Test Acc: 59.87%, Acc Diff: 26.93%, LR: 0.009955 (OVERFITTING: 14 epochs)
2025-10-11 12:49:41,868 - CIFAR-100_Training - INFO - Starting Epoch 34/100
2025-10-11 12:52:04,553 - CIFAR-100_Training - INFO - Epoch 34: Train Loss: 0.4028, Train Acc: 87.49%, Test Loss: 1.8297, Test Acc: 59.95%, Acc Diff: 27.54%, LR: 0.009920 (OVERFITTING: 15 epochs)
2025-10-11 12:52:04,553 - CIFAR-100_Training - INFO - Starting Epoch 35/100
2025-10-11 12:54:27,160 - CIFAR-100_Training - INFO - Epoch 35: Train Loss: 0.3842, Train Acc: 88.09%, Test Loss: 1.8164, Test Acc: 60.12%, Acc Diff: 27.97%, LR: 0.009875 (OVERFITTING: 16 epochs)
2025-10-11 12:54:27,160 - CIFAR-100_Training - INFO - Starting Epoch 36/100
2025-10-11 12:56:49,785 - CIFAR-100_Training - INFO - Epoch 36: Train Loss: 0.3553, Train Acc: 89.02%, Test Loss: 1.8290, Test Acc: 59.56%, Acc Diff: 29.46%, LR: 0.009820 (OVERFITTING: 17 epochs)
2025-10-11 12:56:49,785 - CIFAR-100_Training - INFO - Starting Epoch 37/100
2025-10-11 12:59:12,257 - CIFAR-100_Training - INFO - Epoch 37: Train Loss: 0.3370, Train Acc: 89.68%, Test Loss: 1.8189, Test Acc: 60.57%, Acc Diff: 29.11%, LR: 0.009755 (OVERFITTING: 18 epochs)
2025-10-11 12:59:12,257 - CIFAR-100_Training - INFO - Starting Epoch 38/100
2025-10-11 13:01:35,257 - CIFAR-100_Training - INFO - Epoch 38: Train Loss: 0.3069, Train Acc: 90.42%, Test Loss: 1.8076, Test Acc: 60.41%, Acc Diff: 30.01%, LR: 0.009681 (OVERFITTING: 19 epochs)
2025-10-11 13:01:35,257 - CIFAR-100_Training - INFO - Starting Epoch 39/100
2025-10-11 13:04:05,096 - CIFAR-100_Training - INFO - Epoch 39: Train Loss: 0.2919, Train Acc: 90.88%, Test Loss: 1.7693, Test Acc: 60.13%, Acc Diff: 30.75%, LR: 0.009597 (OVERFITTING: 20 epochs)
2025-10-11 13:04:05,096 - CIFAR-100_Training - INFO - Starting Epoch 40/100
2025-10-11 13:06:37,301 - CIFAR-100_Training - INFO - Epoch 40: Train Loss: 0.2802, Train Acc: 91.32%, Test Loss: 1.7610, Test Acc: 61.52%, Acc Diff: 29.80%, LR: 0.009505 (OVERFITTING: 21 epochs)
2025-10-11 13:06:37,301 - CIFAR-100_Training - INFO - Starting Epoch 41/100
2025-10-11 13:09:08,120 - CIFAR-100_Training - INFO - Epoch 41: Train Loss: 0.2514, Train Acc: 92.23%, Test Loss: 1.7511, Test Acc: 61.60%, Acc Diff: 30.63%, LR: 0.009403 (OVERFITTING: 22 epochs)
2025-10-11 13:09:08,120 - CIFAR-100_Training - INFO - Starting Epoch 42/100
2025-10-11 13:11:37,374 - CIFAR-100_Training - INFO - Epoch 42: Train Loss: 0.2473, Train Acc: 92.35%, Test Loss: 1.8320, Test Acc: 61.15%, Acc Diff: 31.20%, LR: 0.009292 (OVERFITTING: 23 epochs)
2025-10-11 13:11:37,374 - CIFAR-100_Training - INFO - Starting Epoch 43/100
2025-10-11 13:14:02,669 - CIFAR-100_Training - INFO - Epoch 43: Train Loss: 0.2477, Train Acc: 92.23%, Test Loss: 1.8233, Test Acc: 61.48%, Acc Diff: 30.75%, LR: 0.009173 (OVERFITTING: 24 epochs)
2025-10-11 13:14:02,669 - CIFAR-100_Training - INFO - Starting Epoch 44/100
2025-10-11 13:16:41,228 - CIFAR-100_Training - INFO - Epoch 44: Train Loss: 0.2235, Train Acc: 93.18%, Test Loss: 1.8055, Test Acc: 62.16%, Acc Diff: 31.02%, LR: 0.009045 (OVERFITTING: 25 epochs)
2025-10-11 13:16:41,228 - CIFAR-100_Training - INFO - Starting Epoch 45/100
2025-10-11 13:19:13,371 - CIFAR-100_Training - INFO - Epoch 45: Train Loss: 0.2093, Train Acc: 93.61%, Test Loss: 1.8390, Test Acc: 61.91%, Acc Diff: 31.70%, LR: 0.008909 (OVERFITTING: 26 epochs)
2025-10-11 13:19:13,371 - CIFAR-100_Training - INFO - Starting Epoch 46/100
2025-10-11 13:21:44,274 - CIFAR-100_Training - INFO - Epoch 46: Train Loss: 0.1991, Train Acc: 93.89%, Test Loss: 1.8003, Test Acc: 62.29%, Acc Diff: 31.60%, LR: 0.008765 (OVERFITTING: 27 epochs)
2025-10-11 13:21:44,274 - CIFAR-100_Training - INFO - Starting Epoch 47/100
2025-10-11 13:24:11,370 - CIFAR-100_Training - INFO - Epoch 47: Train Loss: 0.1897, Train Acc: 94.14%, Test Loss: 1.8709, Test Acc: 62.22%, Acc Diff: 31.92%, LR: 0.008614 (OVERFITTING: 28 epochs)
2025-10-11 13:24:11,370 - CIFAR-100_Training - INFO - Starting Epoch 48/100
2025-10-11 13:26:43,110 - CIFAR-100_Training - INFO - Epoch 48: Train Loss: 0.1837, Train Acc: 94.44%, Test Loss: 1.7645, Test Acc: 63.02%, Acc Diff: 31.42%, LR: 0.008455 (OVERFITTING: 29 epochs)
2025-10-11 13:26:43,110 - CIFAR-100_Training - INFO - Starting Epoch 49/100
2025-10-11 13:29:17,106 - CIFAR-100_Training - INFO - Epoch 49: Train Loss: 0.1775, Train Acc: 94.60%, Test Loss: 1.8237, Test Acc: 62.55%, Acc Diff: 32.05%, LR: 0.008289 (OVERFITTING: 30 epochs)
2025-10-11 13:29:17,106 - CIFAR-100_Training - INFO - Starting Epoch 50/100
2025-10-11 13:31:46,929 - CIFAR-100_Training - INFO - Epoch 50: Train Loss: 0.1669, Train Acc: 94.82%, Test Loss: 1.8328, Test Acc: 62.65%, Acc Diff: 32.17%, LR: 0.008117 (OVERFITTING: 31 epochs)
2025-10-11 13:31:46,929 - CIFAR-100_Training - INFO - Starting Epoch 51/100
2025-10-11 13:34:17,118 - CIFAR-100_Training - INFO - Epoch 51: Train Loss: 0.1518, Train Acc: 95.29%, Test Loss: 1.7398, Test Acc: 64.14%, Acc Diff: 31.15%, LR: 0.007939 (OVERFITTING: 32 epochs)
2025-10-11 13:34:17,118 - CIFAR-100_Training - INFO - Starting Epoch 52/100
2025-10-11 13:36:47,889 - CIFAR-100_Training - INFO - Epoch 52: Train Loss: 0.1420, Train Acc: 95.73%, Test Loss: 1.7989, Test Acc: 63.81%, Acc Diff: 31.92%, LR: 0.007754 (OVERFITTING: 33 epochs)
2025-10-11 13:36:47,889 - CIFAR-100_Training - INFO - Starting Epoch 53/100
2025-10-11 13:39:21,900 - CIFAR-100_Training - INFO - Epoch 53: Train Loss: 0.1397, Train Acc: 95.72%, Test Loss: 1.7795, Test Acc: 63.51%, Acc Diff: 32.21%, LR: 0.007564 (OVERFITTING: 34 epochs)
2025-10-11 13:39:21,901 - CIFAR-100_Training - INFO - Starting Epoch 54/100
2025-10-11 13:41:45,562 - CIFAR-100_Training - INFO - Epoch 54: Train Loss: 0.1307, Train Acc: 96.00%, Test Loss: 1.7731, Test Acc: 64.17%, Acc Diff: 31.83%, LR: 0.007369 (OVERFITTING: 35 epochs)
2025-10-11 13:41:45,562 - CIFAR-100_Training - INFO - Starting Epoch 55/100
2025-10-11 13:44:19,321 - CIFAR-100_Training - INFO - Epoch 55: Train Loss: 0.1293, Train Acc: 96.07%, Test Loss: 1.8019, Test Acc: 63.98%, Acc Diff: 32.09%, LR: 0.007169 (OVERFITTING: 36 epochs)
2025-10-11 13:44:19,321 - CIFAR-100_Training - INFO - Starting Epoch 56/100
2025-10-11 13:46:56,053 - CIFAR-100_Training - INFO - Epoch 56: Train Loss: 0.1272, Train Acc: 96.15%, Test Loss: 1.8054, Test Acc: 64.16%, Acc Diff: 31.99%, LR: 0.006965 (OVERFITTING: 37 epochs)
2025-10-11 13:46:56,053 - CIFAR-100_Training - INFO - Starting Epoch 57/100
2025-10-11 13:49:33,369 - CIFAR-100_Training - INFO - Epoch 57: Train Loss: 0.1099, Train Acc: 96.68%, Test Loss: 1.8019, Test Acc: 64.47%, Acc Diff: 32.21%, LR: 0.006757 (OVERFITTING: 38 epochs)
2025-10-11 13:49:33,369 - CIFAR-100_Training - INFO - Starting Epoch 58/100
2025-10-11 13:52:10,514 - CIFAR-100_Training - INFO - Epoch 58: Train Loss: 0.1052, Train Acc: 96.83%, Test Loss: 1.7886, Test Acc: 64.67%, Acc Diff: 32.16%, LR: 0.006545 (OVERFITTING: 39 epochs)
2025-10-11 13:52:10,514 - CIFAR-100_Training - INFO - Starting Epoch 59/100
2025-10-11 13:54:51,323 - CIFAR-100_Training - INFO - Epoch 59: Train Loss: 0.0998, Train Acc: 97.01%, Test Loss: 1.7431, Test Acc: 64.46%, Acc Diff: 32.55%, LR: 0.006330 (OVERFITTING: 40 epochs)
2025-10-11 13:54:51,323 - CIFAR-100_Training - INFO - Starting Epoch 60/100
2025-10-11 13:57:32,314 - CIFAR-100_Training - INFO - Epoch 60: Train Loss: 0.0953, Train Acc: 97.08%, Test Loss: 1.7629, Test Acc: 64.80%, Acc Diff: 32.28%, LR: 0.006112 (OVERFITTING: 41 epochs)
2025-10-11 13:57:32,314 - CIFAR-100_Training - INFO - Starting Epoch 61/100
2025-10-11 14:00:01,061 - CIFAR-100_Training - INFO - Epoch 61: Train Loss: 0.0928, Train Acc: 97.24%, Test Loss: 1.7507, Test Acc: 65.21%, Acc Diff: 32.03%, LR: 0.005893 (OVERFITTING: 42 epochs)
2025-10-11 14:00:01,061 - CIFAR-100_Training - INFO - Starting Epoch 62/100
