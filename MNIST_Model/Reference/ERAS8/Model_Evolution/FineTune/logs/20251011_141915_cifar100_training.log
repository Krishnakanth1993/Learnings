2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\logs\20251011_141915_cifar100_training.log
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - Updated Configuration (from main()):
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Epochs: 30
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Learning Rate: 0.00251
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Optimizer: SGD
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Weight Decay: 0.0001
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Momentum: 0.9
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Scheduler: OneCycleLR
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Max LR: 0.01
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Pct Start: 0.3
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Div Factor: 5
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Final Div Factor: 1000.0
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Anneal Strategy: cos
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Batch Size: 128
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Num Workers: 4
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Pin Memory: True
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Shuffle: True
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Dropout Rate: 0.0
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Device: CUDA
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\logs
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\models
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Save Model: True
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO -   - Log Level: INFO
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - CIFAR-100 TRAINING EXPERIMENT STARTED
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=128, num_workers=4, pin_memory=True, shuffle=True, cifar100_mean=(0.507076, 0.48655, 0.440919), cifar100_std=(0.267334, 0.256438, 0.27615), rotation_range=(-7.0, 7.0), fill_value=1)
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - Model Config: ModelConfig(input_channels=3, input_size=(32, 32), num_classes=100, dropout_rate=0.0)
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - Training Config: TrainingConfig(epochs=30, learning_rate=0.00251, momentum=0.9, weight_decay=0.0001, scheduler_step_size=10, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='OneCycleLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001, onecycle_max_lr=0.01, onecycle_pct_start=0.3, onecycle_div_factor=5, onecycle_final_div_factor=1000.0, onecycle_anneal_strategy='cos')
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - Setting up data...
2025-10-11 14:19:15,566 - CIFAR-100_Training - INFO - Using Albumentations for data augmentation
2025-10-11 14:19:15,585 - CIFAR-100_Training - INFO - Loading CIFAR-100 dataset...
2025-10-11 14:19:16,865 - CIFAR-100_Training - INFO - CIFAR-100 dataset loaded successfully!
2025-10-11 14:19:16,865 - CIFAR-100_Training - INFO - Train samples: 50000
2025-10-11 14:19:16,865 - CIFAR-100_Training - INFO - Test samples: 10000
2025-10-11 14:19:16,865 - CIFAR-100_Training - INFO - Augmentation library: Albumentations
2025-10-11 14:19:16,865 - CIFAR-100_Training - INFO - Computing CIFAR-100 data statistics...
2025-10-11 14:19:18,608 - CIFAR-100_Training - INFO - CIFAR-100 Data Statistics:
2025-10-11 14:19:18,608 - CIFAR-100_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-10-11 14:19:18,609 - CIFAR-100_Training - INFO -   - Size: 153,600,000
2025-10-11 14:19:18,609 - CIFAR-100_Training - INFO -   - Min: 0.0000
2025-10-11 14:19:18,609 - CIFAR-100_Training - INFO -   - Max: 1.0000
2025-10-11 14:19:18,609 - CIFAR-100_Training - INFO -   - Mean: 0.4782
2025-10-11 14:19:18,609 - CIFAR-100_Training - INFO -   - Std: 0.2682
2025-10-11 14:19:18,610 - CIFAR-100_Training - INFO -   - Variance: 0.0719
2025-10-11 14:19:18,610 - CIFAR-100_Training - INFO - Channel-wise Statistics:
2025-10-11 14:19:18,610 - CIFAR-100_Training - INFO -   Red Channel:
2025-10-11 14:19:18,610 - CIFAR-100_Training - INFO -     - Mean: 0.5071
2025-10-11 14:19:18,610 - CIFAR-100_Training - INFO -     - Std: 0.2673
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -   Green Channel:
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Mean: 0.4865
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Std: 0.2564
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -   Blue Channel:
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Mean: 0.4409
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Std: 0.2762
2025-10-11 14:19:18,611 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 14:19:18,612 - CIFAR-100_Training - INFO -     - Max: 1.0000
