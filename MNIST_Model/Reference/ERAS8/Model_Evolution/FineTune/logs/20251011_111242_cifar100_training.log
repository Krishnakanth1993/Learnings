2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Logger initialized. Log file: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\logs\20251011_111242_cifar100_training.log
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Updated Configuration (from main()):
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Epochs: 100
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Learning Rate: 0.00251
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Optimizer: SGD
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Weight Decay: 0.0001
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Momentum: 0.9
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Scheduler: OneCycleLR
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Max LR: 0.01
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Pct Start: 0.3
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Div Factor: 10.0
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Final Div Factor: 1000.0
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Anneal Strategy: cos
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Batch Size: 128
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Num Workers: 4
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Pin Memory: True
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Shuffle: True
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Dropout Rate: 0.2
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Device: CUDA
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Log Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\logs
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Model Save Directory: C:\Users\krish\Documents\Krishnakanth\Learnings\Learnings\MNIST_Model\Reference\ERAS8\Model_Evolution\FineTune\models
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Save Model: True
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO -   - Log Level: INFO
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - CIFAR-100 TRAINING EXPERIMENT STARTED
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Data Config: DataConfig(data_dir='./data', batch_size=128, num_workers=4, pin_memory=True, shuffle=True, cifar100_mean=(0.507076, 0.48655, 0.440919), cifar100_std=(0.267334, 0.256438, 0.27615), rotation_range=(-7.0, 7.0), fill_value=1)
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Model Config: ModelConfig(input_channels=3, input_size=(32, 32), num_classes=100, dropout_rate=0.2)
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Training Config: TrainingConfig(epochs=100, learning_rate=0.00251, momentum=0.9, weight_decay=0.0001, scheduler_step_size=10, scheduler_gamma=0.1, seed=1, optimizer_type='SGD', adam_betas=(0.9, 0.999), adam_eps=1e-08, rmsprop_alpha=0.99, scheduler_type='OneCycleLR', cosine_t_max=20, exponential_gamma=0.95, plateau_mode='min', plateau_factor=0.5, plateau_patience=5, plateau_threshold=0.0001, onecycle_max_lr=0.01, onecycle_pct_start=0.3, onecycle_div_factor=10.0, onecycle_final_div_factor=1000.0, onecycle_anneal_strategy='cos')
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Setting up data...
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Using Albumentations for data augmentation
2025-10-11 11:12:42,004 - CIFAR-100_Training - INFO - Loading CIFAR-100 dataset...
2025-10-11 11:12:43,309 - CIFAR-100_Training - INFO - CIFAR-100 dataset loaded successfully!
2025-10-11 11:12:43,309 - CIFAR-100_Training - INFO - Train samples: 50000
2025-10-11 11:12:43,309 - CIFAR-100_Training - INFO - Test samples: 10000
2025-10-11 11:12:43,309 - CIFAR-100_Training - INFO - Augmentation library: Albumentations
2025-10-11 11:12:43,309 - CIFAR-100_Training - INFO - Computing CIFAR-100 data statistics...
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO - CIFAR-100 Data Statistics:
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   - Shape: (50000, 32, 32, 3)
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   - Size: 153,600,000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   - Min: 0.0000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   - Max: 1.0000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   - Mean: 0.4782
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   - Std: 0.2682
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   - Variance: 0.0719
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO - Channel-wise Statistics:
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   Red Channel:
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Mean: 0.5071
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Std: 0.2673
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   Green Channel:
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Mean: 0.4865
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Std: 0.2564
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -   Blue Channel:
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Mean: 0.4409
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Std: 0.2762
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Min: 0.0000
2025-10-11 11:12:45,086 - CIFAR-100_Training - INFO -     - Max: 1.0000
2025-10-11 11:12:58,890 - CIFAR-100_Training - INFO - CIFAR-100 Batch Information:
2025-10-11 11:12:58,890 - CIFAR-100_Training - INFO -   - Batch size: 128
2025-10-11 11:12:58,890 - CIFAR-100_Training - INFO -   - Image shape: torch.Size([3, 32, 32])
2025-10-11 11:12:58,890 - CIFAR-100_Training - INFO -   - Label shape: torch.Size([128])
2025-10-11 11:12:58,890 - CIFAR-100_Training - INFO -   - Data type: torch.float32
2025-10-11 11:12:58,890 - CIFAR-100_Training - INFO -   - Number of classes: 100
2025-10-11 11:13:00,107 - CIFAR-100_Training - INFO - Getting input size from CIFAR-100 data loader...
2025-10-11 11:13:11,972 - CIFAR-100_Training - INFO - CIFAR-100 input size from data loader: (3, 32, 32)
2025-10-11 11:13:13,052 - CIFAR-100_Training - INFO - Setting up model...
2025-10-11 11:13:13,376 - CIFAR-100_Training - INFO - Generating ResNet-34 summary...
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO - ResNet-34 Architecture Summary:
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -   - Total Parameters: 21,328,292
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -   - Batch Normalization: Yes
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -   - Dropout: Yes
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -   - FC Layers: Yes
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -   - GAP Layers: Yes
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO - DETAILED MODEL ARCHITECTURE SUMMARY
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO - ----------------------------------------------------------------
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Layer (type)               Output Shape         Param #
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO - ================================================================
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -             Conv2d-1           [-1, 64, 32, 32]           1,728
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BatchNorm2d-2           [-1, 64, 32, 32]             128
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -               ReLU-3           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -             Conv2d-4           [-1, 64, 32, 32]          36,864
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BatchNorm2d-5           [-1, 64, 32, 32]             128
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -               ReLU-6           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -             Conv2d-7           [-1, 64, 32, 32]          36,864
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BatchNorm2d-8           [-1, 64, 32, 32]             128
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -               ReLU-9           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Dropout2d-10           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BasicBlock-11           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-12           [-1, 64, 32, 32]          36,864
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-13           [-1, 64, 32, 32]             128
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-14           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-15           [-1, 64, 32, 32]          36,864
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-16           [-1, 64, 32, 32]             128
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-17           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Dropout2d-18           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BasicBlock-19           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-20           [-1, 64, 32, 32]          36,864
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-21           [-1, 64, 32, 32]             128
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-22           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-23           [-1, 64, 32, 32]          36,864
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-24           [-1, 64, 32, 32]             128
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-25           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Dropout2d-26           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BasicBlock-27           [-1, 64, 32, 32]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-28          [-1, 128, 16, 16]          73,728
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-29          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-30          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-31          [-1, 128, 16, 16]         147,456
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-32          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-33          [-1, 128, 16, 16]           8,192
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-34          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-35          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Dropout2d-36          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BasicBlock-37          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-38          [-1, 128, 16, 16]         147,456
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-39          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-40          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-41          [-1, 128, 16, 16]         147,456
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-42          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-43          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Dropout2d-44          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BasicBlock-45          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-46          [-1, 128, 16, 16]         147,456
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-47          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-48          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-49          [-1, 128, 16, 16]         147,456
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-50          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-51          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Dropout2d-52          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BasicBlock-53          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-54          [-1, 128, 16, 16]         147,456
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-55          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-56          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -            Conv2d-57          [-1, 128, 16, 16]         147,456
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -       BatchNorm2d-58          [-1, 128, 16, 16]             256
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -              ReLU-59          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -         Dropout2d-60          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,943 - CIFAR-100_Training - INFO -        BasicBlock-61          [-1, 128, 16, 16]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -            Conv2d-62            [-1, 256, 8, 8]         294,912
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -       BatchNorm2d-63            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -              ReLU-64            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -            Conv2d-65            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -       BatchNorm2d-66            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -            Conv2d-67            [-1, 256, 8, 8]          32,768
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -       BatchNorm2d-68            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -              ReLU-69            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -         Dropout2d-70            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -        BasicBlock-71            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -            Conv2d-72            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -       BatchNorm2d-73            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -              ReLU-74            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -            Conv2d-75            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -       BatchNorm2d-76            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -              ReLU-77            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -         Dropout2d-78            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -        BasicBlock-79            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -            Conv2d-80            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,957 - CIFAR-100_Training - INFO -       BatchNorm2d-81            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,958 - CIFAR-100_Training - INFO -              ReLU-82            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,958 - CIFAR-100_Training - INFO -            Conv2d-83            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,958 - CIFAR-100_Training - INFO -       BatchNorm2d-84            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,958 - CIFAR-100_Training - INFO -              ReLU-85            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,958 - CIFAR-100_Training - INFO -         Dropout2d-86            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -        BasicBlock-87            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -            Conv2d-88            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -       BatchNorm2d-89            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -              ReLU-90            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -            Conv2d-91            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -       BatchNorm2d-92            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -              ReLU-93            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -         Dropout2d-94            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -        BasicBlock-95            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -            Conv2d-96            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -       BatchNorm2d-97            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -              ReLU-98            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -            Conv2d-99            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -      BatchNorm2d-100            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -             ReLU-101            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -        Dropout2d-102            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,959 - CIFAR-100_Training - INFO -       BasicBlock-103            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -           Conv2d-104            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -      BatchNorm2d-105            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -             ReLU-106            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -           Conv2d-107            [-1, 256, 8, 8]         589,824
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -      BatchNorm2d-108            [-1, 256, 8, 8]             512
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -             ReLU-109            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -        Dropout2d-110            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -       BasicBlock-111            [-1, 256, 8, 8]               0
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -           Conv2d-112            [-1, 512, 4, 4]       1,179,648
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -      BatchNorm2d-113            [-1, 512, 4, 4]           1,024
2025-10-11 11:13:13,960 - CIFAR-100_Training - INFO -             ReLU-114            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -           Conv2d-115            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -      BatchNorm2d-116            [-1, 512, 4, 4]           1,024
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -           Conv2d-117            [-1, 512, 4, 4]         131,072
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -      BatchNorm2d-118            [-1, 512, 4, 4]           1,024
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -             ReLU-119            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -        Dropout2d-120            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -       BasicBlock-121            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -           Conv2d-122            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -      BatchNorm2d-123            [-1, 512, 4, 4]           1,024
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -             ReLU-124            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -           Conv2d-125            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -      BatchNorm2d-126            [-1, 512, 4, 4]           1,024
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -             ReLU-127            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -        Dropout2d-128            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -       BasicBlock-129            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,961 - CIFAR-100_Training - INFO -           Conv2d-130            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -      BatchNorm2d-131            [-1, 512, 4, 4]           1,024
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -             ReLU-132            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -           Conv2d-133            [-1, 512, 4, 4]       2,359,296
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -      BatchNorm2d-134            [-1, 512, 4, 4]           1,024
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -             ReLU-135            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -        Dropout2d-136            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -       BasicBlock-137            [-1, 512, 4, 4]               0
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - AdaptiveAvgPool2d-138            [-1, 512, 1, 1]               0
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -          Dropout-139                  [-1, 512]               0
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO -           Linear-140                  [-1, 100]          51,300
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - ================================================================
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Total params: 21,328,292
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Trainable params: 21,328,292
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Non-trainable params: 0
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - ----------------------------------------------------------------
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Input size (MB): 0.01
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Forward/backward pass size (MB): 29.88
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Params size (MB): 81.36
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Estimated Total Size (MB): 111.26
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - ----------------------------------------------------------------
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - ==================================================
2025-10-11 11:13:13,963 - CIFAR-100_Training - INFO - Setting up trainer...
2025-10-11 11:13:13,967 - CIFAR-100_Training - INFO - Using device: cuda
2025-10-11 11:13:13,967 - CIFAR-100_Training - INFO - Early stopping: Stop if train_acc - test_acc > 15.0% for 10 epochs
2025-10-11 11:13:13,967 - CIFAR-100_Training - INFO - Starting training process...
2025-10-11 11:13:13,967 - CIFAR-100_Training - INFO - Starting training process...
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO - Using optimizer: SGD
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO - Using scheduler: OneCycleLR
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO - Optimizer Configuration:
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO -   - Learning Rate: 0.00251
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO -   - Momentum: 0.9
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO -   - Weight Decay: 0.0001
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO - Scheduler Configuration:
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO -   - Max LR: 0.01
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO -   - Steps per Epoch: 391
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO -   - Pct Start: 0.3
2025-10-11 11:13:13,968 - CIFAR-100_Training - INFO -   - Div Factor: 10.0
2025-10-11 11:13:13,970 - CIFAR-100_Training - INFO -   - Final Div Factor: 1000.0
2025-10-11 11:13:13,970 - CIFAR-100_Training - INFO -   - Anneal Strategy: cos
2025-10-11 11:13:13,970 - CIFAR-100_Training - INFO - Starting Epoch 1/100
2025-10-11 11:15:39,850 - CIFAR-100_Training - INFO - Epoch  1: Train Loss: 4.7082, Train Acc: 1.42%, Test Loss: 4.6587, Test Acc: 1.27%, Acc Diff: 0.15%, LR: 0.001025
2025-10-11 11:15:39,850 - CIFAR-100_Training - INFO - Starting Epoch 2/100
2025-10-11 11:18:06,303 - CIFAR-100_Training - INFO - Epoch  2: Train Loss: 4.5119, Train Acc: 2.17%, Test Loss: 4.7236, Test Acc: 1.43%, Acc Diff: 0.74%, LR: 0.001098
2025-10-11 11:18:06,315 - CIFAR-100_Training - INFO - Starting Epoch 3/100
2025-10-11 11:20:32,469 - CIFAR-100_Training - INFO - Epoch  3: Train Loss: 4.4252, Train Acc: 2.74%, Test Loss: 4.7811, Test Acc: 1.38%, Acc Diff: 1.36%, LR: 0.001220
2025-10-11 11:20:32,469 - CIFAR-100_Training - INFO - Starting Epoch 4/100
2025-10-11 11:22:58,118 - CIFAR-100_Training - INFO - Epoch  4: Train Loss: 4.3674, Train Acc: 3.10%, Test Loss: 4.7339, Test Acc: 1.66%, Acc Diff: 1.44%, LR: 0.001389
2025-10-11 11:22:58,118 - CIFAR-100_Training - INFO - Starting Epoch 5/100
2025-10-11 11:25:23,761 - CIFAR-100_Training - INFO - Epoch  5: Train Loss: 4.3281, Train Acc: 3.42%, Test Loss: 4.6832, Test Acc: 1.78%, Acc Diff: 1.64%, LR: 0.001603
2025-10-11 11:25:23,761 - CIFAR-100_Training - INFO - Starting Epoch 6/100
2025-10-11 11:27:50,778 - CIFAR-100_Training - INFO - Epoch  6: Train Loss: 4.2980, Train Acc: 3.58%, Test Loss: 4.6404, Test Acc: 1.84%, Acc Diff: 1.74%, LR: 0.001860
2025-10-11 11:27:50,778 - CIFAR-100_Training - INFO - Starting Epoch 7/100
